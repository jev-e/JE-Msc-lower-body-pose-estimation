{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data From CSV Recording\n",
    "\n",
    "## Load File\n",
    "\n",
    "Data is loaded from a CSV recording file, accepted through an input prompt. This includes all positional data related to the 6 trackers (HMD, Left Controller, Right Controller, Waist, Left Foot, Right Foot).\n",
    "\n",
    "'Data is loaded into a Pandas dataframe. The primary tracking data is then extracted, leaving extraneous data such as booleans for button presses.\n",
    "\n",
    "The extracted columns are then concatenated into a new dataframe, and the columns are renamed for ease of reading.\n",
    "\n",
    "The columns are reorded in the order of head/r_controller/l_controller/waist/r_foot/l_foot.\n",
    "\n",
    "The new trimmed file is written to a directory (/test_data or /train_data), for further manipulation and loading into the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Read in CSV\n",
    "def GetRecording(path):\n",
    "    recording_path = \"../recordings/\"\n",
    "    file_name = input(\"Input Recording File Name\")\n",
    "    try:\n",
    "        dataframe = pd.read_csv(recording_path + file_name + \".csv\")\n",
    "        return dataframe, file_name\n",
    "    except: \n",
    "        print(\"Error Reading File: Check Spelling and Try Again\")\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "#Seperate each tracker to seperate dataframe\n",
    "\n",
    "def GetColByName(dataframe):\n",
    "    HMD = dataframe.loc[:, [\"HMD0_tx\", \"HMD0_ty\", \"HMD0_tz\"]]\n",
    "    \n",
    "    controller_1 = dataframe.loc[:, ['controller3_tx', 'controller3_ty', 'controller3_tz']]\n",
    "\n",
    "    controller_2 = dataframe.loc[:, ['controller4_tx', 'controller4_ty', 'controller4_tz']]\n",
    "\n",
    "    tracker_1 = dataframe.loc[:, ['generic7_tx', 'generic7_ty', 'generic7_tz']]\n",
    "\n",
    "    tracker_2 = dataframe.loc[:, ['generic8_tx', 'generic8_ty', 'generic8_tz']]\n",
    "\n",
    "    tracker_3 = dataframe.loc[:, ['generic9_tx', 'generic9_ty', 'generic9_tz']]\n",
    "\n",
    "    joined = pd.concat([HMD,controller_1, controller_2, tracker_1 ,tracker_2 ,tracker_3], axis=1)\n",
    "    return joined\n",
    "\n",
    "def AssignTracker(dataframe):\n",
    "    display(dataframe.iloc[0:1,:])\n",
    "    trackerNum = 7\n",
    "    for x in range(3):\n",
    "        trackerStr = str(trackerNum)\n",
    "        tracker = input('assign generic' + trackerStr)\n",
    "        dataframe.rename(columns={'generic' + trackerStr + '_tx': tracker + '_x', 'generic' + trackerStr + '_ty': tracker + \"_y\", 'generic' + trackerStr + '_tz': tracker + '_z'}, inplace=True)\n",
    "        trackerNum += 1\n",
    "        \n",
    "    controllerNum = 3\n",
    "    for x in range(2):\n",
    "        controllerStr = str(controllerNum)\n",
    "        controller = input('assign controller' + controllerStr)\n",
    "        dataframe.rename(columns={'controller' + controllerStr + '_tx': controller + '_x', 'controller' + controllerStr + '_ty': controller + \"_y\", 'controller' + controllerStr + '_tz': controller + '_z'}, inplace=True)\n",
    "        controllerNum += 1\n",
    "    dataframe.rename(columns={'HMD0_tx': 'head_x', 'HMD0_ty': 'head_y', 'HMD0_tz': 'head_z'}, inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "def GetDirectory():\n",
    "    choice = input(\"train or test data:\")\n",
    "    if choice == \"test\":\n",
    "        output_path = \"../test_data/\"\n",
    "    else:\n",
    "        output_path = \"../train_data/\"\n",
    "    return output_path\n",
    "\n",
    "def OrderFeatures(dataframe):\n",
    "    head = dataframe.loc[:, ['head_x', 'head_y', 'head_z']]\n",
    "    l_controller = dataframe.loc[:, ['l_controller_x', 'l_controller_y', 'l_controller_z']]\n",
    "    r_controller = dataframe.loc[:, ['r_controller_x', 'r_controller_y', 'r_controller_z']]\n",
    "    waist = dataframe.loc[:, ['waist_x', 'waist_y', 'waist_z']]\n",
    "    r_foot = dataframe.loc[:, ['r_foot_x', 'r_foot_y', 'r_foot_z']]\n",
    "    l_foot = dataframe.loc[:, ['l_foot_x', 'l_foot_y', 'l_foot_z']]\n",
    "    reordered = pd.concat([head , r_controller, l_controller, waist, r_foot, l_foot], axis=1)\n",
    "    return reordered\n",
    "\n",
    "    \n",
    "    \n",
    "def WriteOutput(path, dataframe, filename):\n",
    "    output_file = path + filename + \"_trimmed.csv\"\n",
    "    dataframe.to_csv(output_file, index = False)\n",
    "    print(file_name + \" output to \" + path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run data trimming functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input Recording File Name leg_raise_5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HMD0_tx</th>\n",
       "      <th>HMD0_ty</th>\n",
       "      <th>HMD0_tz</th>\n",
       "      <th>controller3_tx</th>\n",
       "      <th>controller3_ty</th>\n",
       "      <th>controller3_tz</th>\n",
       "      <th>controller4_tx</th>\n",
       "      <th>controller4_ty</th>\n",
       "      <th>controller4_tz</th>\n",
       "      <th>generic7_tx</th>\n",
       "      <th>generic7_ty</th>\n",
       "      <th>generic7_tz</th>\n",
       "      <th>generic8_tx</th>\n",
       "      <th>generic8_ty</th>\n",
       "      <th>generic8_tz</th>\n",
       "      <th>generic9_tx</th>\n",
       "      <th>generic9_ty</th>\n",
       "      <th>generic9_tz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.964998</td>\n",
       "      <td>158.131058</td>\n",
       "      <td>3.838474</td>\n",
       "      <td>-18.907917</td>\n",
       "      <td>92.860924</td>\n",
       "      <td>-9.813828</td>\n",
       "      <td>29.159588</td>\n",
       "      <td>80.373276</td>\n",
       "      <td>2.166218</td>\n",
       "      <td>3.899813</td>\n",
       "      <td>97.88607</td>\n",
       "      <td>6.474656</td>\n",
       "      <td>21.754217</td>\n",
       "      <td>11.036432</td>\n",
       "      <td>13.468838</td>\n",
       "      <td>-12.954676</td>\n",
       "      <td>11.488569</td>\n",
       "      <td>19.045788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HMD0_tx     HMD0_ty   HMD0_tz  controller3_tx  controller3_ty  \\\n",
       "0  1.964998  158.131058  3.838474      -18.907917       92.860924   \n",
       "\n",
       "   controller3_tz  controller4_tx  controller4_ty  controller4_tz  \\\n",
       "0       -9.813828       29.159588       80.373276        2.166218   \n",
       "\n",
       "   generic7_tx  generic7_ty  generic7_tz  generic8_tx  generic8_ty  \\\n",
       "0     3.899813     97.88607     6.474656    21.754217    11.036432   \n",
       "\n",
       "   generic8_tz  generic9_tx  generic9_ty  generic9_tz  \n",
       "0    13.468838   -12.954676    11.488569    19.045788  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "assign generic7 waist\n",
      "assign generic8 r_foot\n",
      "assign generic9 l_foot\n",
      "assign controller3 l_controller\n",
      "assign controller4 r_controller\n",
      "train or test data: test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leg_raise_5 output to ../test_data/\n"
     ]
    }
   ],
   "source": [
    "recording_path = \" ../recordings\"\n",
    "\n",
    "dataframe, file_name = GetRecording(recording_path)\n",
    "joined = GetColByName(dataframe)\n",
    "renamed = AssignTracker(joined)\n",
    "path = GetDirectory()\n",
    "reordered = OrderFeatures(renamed)\n",
    "WriteOutput(path, reordered, file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization\n",
    "\n",
    "## Data Scaling\n",
    "\n",
    "The new CSV is loaded into memory, chosen through an input prompt\n",
    "The data is then split between the features (the HMD and controller tracking data), and the labels (the waist and foot trackers).\n",
    "These are loaded into Numpy arrays to peform normaliztion. The output from OpenVR Recorder is upscaled by 100. To correct this the array is divided by 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "#import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "output_path = \"../trim_output/\"\n",
    "\n",
    "\n",
    "#read in formatted CSV\n",
    "def ReadCSV(path):\n",
    "    file_name = input(\"Input File Name\")\n",
    "    file_list = []\n",
    "    file_list.append(file_name)\n",
    "    try:\n",
    "        dataframe = pd.read_csv(path + file_name + \".csv\")\n",
    "        print(\"Dataframe created\")\n",
    "    except:\n",
    "        print(\"Error Reading File\")\n",
    "    return dataframe, file_list\n",
    "\n",
    "def SplitFeaturesLabels(dataframe):\n",
    "    x = dataframe.iloc[:, 0:9]\n",
    "    y = dataframe.iloc[:, 9:18]\n",
    "    return x, y\n",
    "\n",
    "#Load data into Numpy array\n",
    "def LoadArray(x, y):\n",
    "    x_array = np.array(x)\n",
    "    y_array = np.array(y)\n",
    "    return x_array, y_array\n",
    "\n",
    "\n",
    "def NormalizeValues (x, y):\n",
    "    x =  np.divide(x, 100)\n",
    "    y =  np.divide(y, 100)\n",
    "    return x, y\n",
    "\n",
    "def SampleSize(x, y):\n",
    "    x_samples = x[0:600,:]\n",
    "    y_samples = y[0:600,:]\n",
    "    return x_samples, y_samples\n",
    "\n",
    "def RoundValues(x, y): \n",
    "    x_rounded = np.around(x, 3)\n",
    "    y_rounded = np.around(y, 3)\n",
    "    return x_rounded, y_rounded\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input File Name walking_7_trimmed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe created\n",
      "['walking_7_trimmed']\n",
      "(600, 9) [[0.56456936 1.65256363 0.82371849 ... 0.35004543 0.81725983 0.93927994]\n",
      " [0.56244183 1.6511261  0.82760582 ... 0.35082798 0.81521797 0.94517693]\n",
      " [0.56021255 1.64923187 0.8309227  ... 0.3510099  0.81342445 0.95069672]\n",
      " ...\n",
      " [0.42225151 1.55701126 0.6327589  ... 0.21533564 0.75101753 0.71076973]\n",
      " [0.41390022 1.55681183 0.62624306 ... 0.20336998 0.75672852 0.69413803]\n",
      " [0.40570499 1.55652176 0.6195657  ... 0.19236187 0.76251534 0.67823952]]\n",
      "(600, 9) [[0.56388847 0.9584938  0.82307373 ... 0.6701664  0.12568272 1.02205978]\n",
      " [0.5649939  0.95908966 0.8268927  ... 0.67017311 0.12555384 1.02190422]\n",
      " [0.5658884  0.95991432 0.83057884 ... 0.67164154 0.12405634 1.02306038]\n",
      " ...\n",
      " [0.4459425  0.94995354 0.64034004 ... 0.39146503 0.11636929 0.66756081]\n",
      " [0.43529736 0.9514679  0.63556534 ... 0.39199577 0.115468   0.66869583]\n",
      " [0.42703381 0.95304367 0.63249866 ... 0.39176373 0.11532265 0.66892319]]\n"
     ]
    }
   ],
   "source": [
    "train_path = \"../train_data/\"\n",
    "#load train data from csv\n",
    "train_dataframe, files = ReadCSV(train_path)\n",
    "\n",
    "print(files)\n",
    "#split features and labels into seperate dataframes\n",
    "x_train_df, y_train_df = SplitFeaturesLabels(train_dataframe)\n",
    "\n",
    "#convert features and labels to numpy array\n",
    "x_train, y_train = LoadArray(x_train_df, y_train_df)\n",
    "\n",
    "#Divide values in array by 100\n",
    "x_samples, y_samples = NormalizeValues(x_train, y_train)\n",
    "\n",
    "print(x_samples.shape, x_samples)\n",
    "print(y_samples.shape, y_samples)\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x_train_normalized, y_train_normalized)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(x_samples.max())\n",
    "print(x_samples.min())\n",
    "\n",
    "print(y_samples.max())\n",
    "print(y_samples.min())\n",
    "\n",
    "scaler =MinMaxScaler()\n",
    "print(x_samples[0:1])\n",
    "scaled = scaler.fit(x_samples)\n",
    "print(scaler.transform(x_samples[0:1]))\n",
    "print(scaler.inverse_transform(x_samples[0:1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ReshapeData(x, y):\n",
    "    x_reshaped = np.expand_dims(x, axis=1)\n",
    "    y_reshaped = np.expand_dims(y, axis=1)\n",
    "\n",
    "    return x_reshaped, y_reshaped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 1, 9) (600, 1, 9)\n",
      "1\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "x, y = ReshapeData(x_samples, y_samples)\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "print(x.shape[1])\n",
    "\n",
    "print(x.shape[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test / Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input File Name walking_7_trimmed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Reading File\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'dataframe' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [67]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Create a single test data file\u001b[39;00m\n\u001b[0;32m      3\u001b[0m test_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../test_data/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m test_dataframe \u001b[38;5;241m=\u001b[39m \u001b[43mReadCSV\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#split features and labels into seperate dataframes\u001b[39;00m\n\u001b[0;32m      9\u001b[0m x_test_df, y_test_df \u001b[38;5;241m=\u001b[39m SplitFeaturesLabels(test_dataframe)\n",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36mReadCSV\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError Reading File\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataframe\u001b[49m, file_name\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'dataframe' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#Create a single test data file\n",
    "\n",
    "test_path = \"../test_data/\"\n",
    "\n",
    "\n",
    "test_dataframe = ReadCSV(test_path)\n",
    "\n",
    "#split features and labels into seperate dataframes\n",
    "x_test_df, y_test_df = SplitFeaturesLabels(test_dataframe)\n",
    "\n",
    "#convert features and labels to numpy array\n",
    "x_test, y_test = LoadArray(x_test_df, y_test_df)\n",
    "\n",
    "#Divide values in array by 100\n",
    "x_test_normalized, y_test_normalized = NormalizeValues(x_test, y_test)\n",
    "\n",
    "x_test_samples, y_test_samples = SampleSize(x_test_normalized, y_test_normalized)\n",
    "\n",
    "x, y = ReshapeData(x_test_samples, y_test_samples)\n",
    "\n",
    "print(x.shape, y_test.shape)\n",
    "\n",
    "print(x_test.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Test and Train datasets\n",
    "\n",
    "Combine all data sets in /train_data and /test_data into one, for more samples when training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Combine all datasets in a directory into one dataframe\n",
    "def CombineDatasets(path):\n",
    "    data_list = []\n",
    "    for file in os.listdir(path):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".csv\"):\n",
    "            df = pd.read_csv(path + filename)\n",
    "            \n",
    "            data_list.append(df)\n",
    "         \n",
    "\n",
    "    data_df = pd.concat(data_list, axis=0, ignore_index=True)\n",
    "    return data_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#combine data in a directory into two lists of x and y features\n",
    "def DatasetsLists(path):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    file_list = []\n",
    "    for file in os.listdir(path):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_list.append(filename)\n",
    "            df = pd.read_csv(path + filename)\n",
    "            x_features, y_features = SplitFeaturesLabels(df)\n",
    "            x_train, y_train = LoadArray(x_features, y_features)\n",
    "            x_normalized, y_normalized = NormalizeValues(x_train, y_train)\n",
    "            x_reshape, y_reshape = ReshapeData(x_normalized, y_normalized)\n",
    "            x_list.append(x_reshape)\n",
    "            y_list.append(y_reshape)\n",
    "    return x_list, y_list, file_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arm_raise_1_trimmed.csv', 'arm_raise_3_trimmed.csv', 'boxing_1_trimmed.csv', 'crouch_walking_1_trimmed.csv', 'jumping_1_trimmed.csv', 'jumping_2_trimmed.csv', 'jumping_3_trimmed.csv', 'leg_raise_1_trimmed.csv', 'leg_raise_2_trimmed.csv', 'leg_raise_3_trimmed.csv', 'leg_raise_4_trimmed.csv', 'picking_up_1_trimmed.csv', 'running_on_spot_2_trimmed.csv', 'sitting_on_floor_1_trimmed.csv', 'sitting_standing_1_trimmed.csv', 'sitting_standing_2_trimmed.csv', 'sitting_standing_3_trimmed.csv', 'walking_1_train.csv', 'walking_2_test.csv', 'walking_3_trimmed.csv', 'walking_5_trimmed.csv', 'walking_6_trimmed.csv', 'walking_7_trimmed.csv']\n"
     ]
    }
   ],
   "source": [
    "train_path = \"../train_data/\"\n",
    "x, y, files = DatasetsLists(train_path)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all data in the training data directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16108, 1, 9) (16108, 1, 9)\n"
     ]
    }
   ],
   "source": [
    "train_path = \"../train_data/\"\n",
    "\n",
    "combined_train_dataframe = CombineDatasets(train_path)\n",
    "\n",
    "x_train, y_train = SplitFeaturesLabels(combined_train_dataframe)\n",
    "        \n",
    "x_train_arr, y_train_arr = LoadArray(x_train, y_train)\n",
    "\n",
    "#Divide values in array by 100\n",
    "x_train_normalized, y_train_normalized = NormalizeValues(x_train_arr, y_train_arr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_train, y_train = ReshapeData(x_train_normalized, y_train_normalized)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all data in the test data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5400, 1, 9)\n",
      "[[[ 0.07488835  1.60079437 -0.06116605  0.29804235  0.82701195\n",
      "   -0.13233584 -0.16509771  0.80914047 -0.10186529]]]\n",
      "(5400, 9)\n"
     ]
    }
   ],
   "source": [
    "test_path = \"../test_data/\"\n",
    "\n",
    "combined_test_dataframe = CombineDatasets(test_path)\n",
    "\n",
    "x_test, y_test = SplitFeaturesLabels(combined_test_dataframe)\n",
    "        \n",
    "x_test_arr, y_test_arr = LoadArray(x_test, y_test)\n",
    "\n",
    "x_test_normalized, y_test_normalized = NormalizeValues(x_test_arr, y_test_arr)\n",
    "\n",
    "\n",
    "x_test, y_test = ReshapeData(x_test_normalized, y_test_normalized)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(x_test[0:1,:,:])\n",
    "print(x_test_normalized.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required modules\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, BatchNormalization\n",
    "import tensorflow as tf\n",
    "from keras.layers import LSTM, GRU\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model to two equally sized lists of x features and y labels \n",
    "\n",
    "def FitToList(x, y, model, epoch, b_size, verbose):\n",
    "    for i in range(len(x)):\n",
    "        print(i)\n",
    "        print(x[i].shape)\n",
    "        print(y[i].shape)\n",
    "        model.fit(x[i], y[i], epochs=epoch,batch_size=b_size, verbose=verbose)\n",
    "    return epoch, b_size\n",
    "        \n",
    " # fit the model to a given set of features (x) and labels (y)    \n",
    "def FitModel(x, y, model, epoch, b_size):\n",
    "    model.fit(x, y, validation_split=0.33, epochs=epoch,batch_size = b_size)\n",
    "    return epoch, b_size\n",
    "\n",
    "    \n",
    "def EvaluateModel(x, y, model):\n",
    "    metrics = model.evaluate(x, y, batch_size=256)\n",
    "    print(\"test loss, test acc:\", metrics)\n",
    "    return metrics\n",
    "    \n",
    "    \n",
    "def PredictModel(x, y, model):\n",
    "    predictions = model.predict(x)\n",
    "    y_reshaped = y.reshape(-1,9)\n",
    "    return predictions, y_reshaped\n",
    "\n",
    "\n",
    "def DisplayPredictions(prediction, actual, range_1, range_2):\n",
    "    if range_2 <= 0:\n",
    "        r_1 = 0\n",
    "        r_2 = len(prediction)\n",
    "    else:\n",
    "        r_1 = range_1\n",
    "        r_2 = range_2\n",
    "    print(\"predictions shape:\", prediction.shape)\n",
    "    prediction_df = pd.DataFrame(prediction, columns=[\"Waist_X\", \"Waist_Y\", \"Waist_Z\", \"R_Foot_X\", \"R_Foot_Y\", \"R_Foot_Z\", \"L_Foot_X\", \"L_Foot_Y\", \"L_Foot_Z\"])\n",
    "    actual_df = pd.DataFrame(actual, columns=[\"Waist_X\", \"Waist_Y\", \"Waist_Z\", \"R_Foot_X\", \"R_Foot_Y\", \"R_Foot_Z\", \"L_Foot_X\", \"L_Foot_Y\", \"L_Foot_Z\"])\n",
    "    print(\"Actual Values\")\n",
    "    display(actual_df[r_1:r_2])\n",
    "    print(\"Predicited Values\")\n",
    "    display(prediction_df[r_1:r_2])\n",
    "    return actual_df, prediction_df\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model compiled\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 1, 16)             1296      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 16)             0         \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 16)                1632      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,081\n",
      "Trainable params: 3,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(learning_rate=0.001, momentum=0.8, decay=0.999, nesterov=False)\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(16, return_sequences=True, input_shape=(5, 9)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(16, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(9, activation = \"linear\"))\n",
    "\n",
    "model.compile(loss='mse', optimizer=\"adam\")\n",
    "\n",
    "print ('model compiled')\n",
    "\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_14 (GRU)                (None, 64)                14400     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 9)                 585       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,985\n",
      "Trainable params: 14,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "opt = SGD(learning_rate = 0.01)\n",
    "\n",
    "compile_params = [\"mse\", \"sgd\", \"accuracy\"]\n",
    "#add one GRU layer of 64 cellss with input shape 1,9\n",
    "model_2.add(GRU(64, input_shape=(1, 9)))\n",
    "#model_2.add(Dropout(0.1))\n",
    "\n",
    "#Add Batch Normalization layer\n",
    "#model_2.add(BatchNormalization())\n",
    "\n",
    "\n",
    "#Add dropout layer\n",
    "#model_2.add(Dropout(0.2))\n",
    "\n",
    "#Add Dense layer with 9 outputs\n",
    "model_2.add(Dense(9))\n",
    "\n",
    "print(model_2.summary())\n",
    "\n",
    "\n",
    "#Compile model\n",
    "model_2.compile(\n",
    "    loss = compile_params[0],\n",
    "    optimizer = opt,\n",
    "    metrics = [compile_params[2]],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 606, 600, 600, 600, 606, 600, 600, 606, 600, 600, 600, 600, 600, 600, 606, 600, 600, 606, 606, 600, 600, 600, 600\n  y sizes: 606, 600, 600, 600, 606, 600, 600, 606, 600, 600, 600, 600, 600, 600, 606, 600, 600, 606, 606, 600, 600, 600, 600\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [115]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m epochs, batch_size \u001b[38;5;241m=\u001b[39m \u001b[43mFitModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [94]\u001b[0m, in \u001b[0;36mFitModel\u001b[1;34m(x, y, model, epoch, b_size)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mFitModel\u001b[39m(x, y, model, epoch, b_size):\n\u001b[1;32m---> 13\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.33\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m epoch, b_size\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py:1653\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1649\u001b[0m   msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1650\u001b[0m       label, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1651\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)))\n\u001b[0;32m   1652\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1653\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 606, 600, 600, 600, 606, 600, 600, 606, 600, 600, 600, 600, 600, 600, 606, 600, 600, 606, 606, 600, 600, 600, 600\n  y sizes: 606, 600, 600, 600, 606, 600, 600, 606, 600, 600, 600, 600, 600, 600, 606, 600, 600, 606, 606, 600, 600, 600, 600\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "epochs, batch_size = FitModel(x, y, model_2, 1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(905, 1, 9)\n",
      "(905, 1, 9)\n",
      "Epoch 1/20\n",
      "905/905 [==============================] - 1s 797us/step - loss: 0.0088 - accuracy: 0.9812\n",
      "Epoch 2/20\n",
      "905/905 [==============================] - 1s 804us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "905/905 [==============================] - 1s 786us/step - loss: 8.8171e-04 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "905/905 [==============================] - 1s 785us/step - loss: 6.2388e-04 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "905/905 [==============================] - 1s 795us/step - loss: 4.4913e-04 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "905/905 [==============================] - 1s 812us/step - loss: 3.3177e-04 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "905/905 [==============================] - 1s 792us/step - loss: 2.5232e-04 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "905/905 [==============================] - 1s 805us/step - loss: 1.9742e-04 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "905/905 [==============================] - 1s 794us/step - loss: 1.5927e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "905/905 [==============================] - 1s 800us/step - loss: 1.3260e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "905/905 [==============================] - 1s 808us/step - loss: 1.1338e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "905/905 [==============================] - 1s 798us/step - loss: 9.9657e-05 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "905/905 [==============================] - 1s 825us/step - loss: 8.9442e-05 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "905/905 [==============================] - 1s 814us/step - loss: 8.2202e-05 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "905/905 [==============================] - 1s 810us/step - loss: 7.6529e-05 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "905/905 [==============================] - 1s 809us/step - loss: 7.2052e-05 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "905/905 [==============================] - 1s 800us/step - loss: 6.8765e-05 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "905/905 [==============================] - 1s 802us/step - loss: 6.5885e-05 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "905/905 [==============================] - 1s 808us/step - loss: 6.3685e-05 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "905/905 [==============================] - 1s 801us/step - loss: 6.1592e-05 - accuracy: 1.0000\n",
      "1\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 884us/step - loss: 5.5499e-04 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 6.8120e-05 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 5.9422e-05 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 998us/step - loss: 5.2570e-05 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 4.7463e-05 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 4.3211e-05 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 4.0020e-05 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 969us/step - loss: 3.7390e-05 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 3.5387e-05 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 3.3804e-05 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 905us/step - loss: 3.2547e-05 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 874us/step - loss: 3.1419e-05 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 891us/step - loss: 3.0474e-05 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 786us/step - loss: 2.9652e-05 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 842us/step - loss: 2.9131e-05 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 780us/step - loss: 2.8577e-05 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 832us/step - loss: 2.8205e-05 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 841us/step - loss: 2.7825e-05 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 806us/step - loss: 2.7381e-05 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 796us/step - loss: 2.7122e-05 - accuracy: 1.0000\n",
      "2\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 887us/step - loss: 7.9934e-04 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 811us/step - loss: 5.3747e-04 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 799us/step - loss: 5.1536e-04 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 824us/step - loss: 4.9738e-04 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 774us/step - loss: 4.7825e-04 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 779us/step - loss: 4.6322e-04 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 4.4655e-04 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 4.3555e-04 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 926us/step - loss: 4.2348e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 863us/step - loss: 4.1201e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 794us/step - loss: 4.0134e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 766us/step - loss: 3.9172e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 750us/step - loss: 3.8270e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 767us/step - loss: 3.7553e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 826us/step - loss: 3.6765e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 1000us/step - loss: 3.6115e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 806us/step - loss: 3.5528e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 874us/step - loss: 3.4916e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 965us/step - loss: 3.4357e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 912us/step - loss: 3.3905e-04 - accuracy: 1.0000\n",
      "3\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 0s 818us/step - loss: 0.0723 - accuracy: 0.3633\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 773us/step - loss: 0.0310 - accuracy: 0.6400\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 765us/step - loss: 0.0272 - accuracy: 0.6717\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 782us/step - loss: 0.0253 - accuracy: 0.6783\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 846us/step - loss: 0.0237 - accuracy: 0.6800\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 797us/step - loss: 0.0223 - accuracy: 0.6867\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 879us/step - loss: 0.0210 - accuracy: 0.7000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 889us/step - loss: 0.0198 - accuracy: 0.7100\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 771us/step - loss: 0.0187 - accuracy: 0.7283\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 772us/step - loss: 0.0177 - accuracy: 0.7517\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 768us/step - loss: 0.0168 - accuracy: 0.7667\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 803us/step - loss: 0.0159 - accuracy: 0.7767\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 843us/step - loss: 0.0151 - accuracy: 0.7917\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 829us/step - loss: 0.0144 - accuracy: 0.7883\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 780us/step - loss: 0.0137 - accuracy: 0.8050\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 768us/step - loss: 0.0132 - accuracy: 0.8050\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 821us/step - loss: 0.0126 - accuracy: 0.8133\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 753us/step - loss: 0.0121 - accuracy: 0.8133\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 793us/step - loss: 0.0117 - accuracy: 0.8133\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 768us/step - loss: 0.0113 - accuracy: 0.8200\n",
      "4\n",
      "(916, 1, 9)\n",
      "(916, 1, 9)\n",
      "Epoch 1/20\n",
      "916/916 [==============================] - 1s 763us/step - loss: 0.0115 - accuracy: 0.9978\n",
      "Epoch 2/20\n",
      "916/916 [==============================] - 1s 850us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "916/916 [==============================] - 1s 839us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "916/916 [==============================] - 1s 909us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "916/916 [==============================] - 1s 766us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "916/916 [==============================] - 1s 865us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "916/916 [==============================] - 1s 915us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "916/916 [==============================] - 1s 825us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "916/916 [==============================] - 1s 759us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "916/916 [==============================] - 1s 842us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "916/916 [==============================] - 1s 965us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "916/916 [==============================] - 1s 908us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "916/916 [==============================] - 1s 841us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "916/916 [==============================] - 1s 815us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "916/916 [==============================] - 1s 770us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "916/916 [==============================] - 1s 769us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "916/916 [==============================] - 1s 790us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "916/916 [==============================] - 1s 790us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "916/916 [==============================] - 1s 867us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "916/916 [==============================] - 1s 803us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "5\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 882us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 758us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 785us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 992us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 814us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 975us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 941us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 826us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 957us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 934us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 900us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 882us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 916us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 975us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 950us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 936us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "6\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 904us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 941us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 958us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 822us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 847us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 786us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 931us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 808us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 843us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 818us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 828us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 795us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 826us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "7\n",
      "(934, 1, 9)\n",
      "(934, 1, 9)\n",
      "Epoch 1/20\n",
      "934/934 [==============================] - 1s 834us/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "934/934 [==============================] - 1s 831us/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "934/934 [==============================] - 1s 902us/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "934/934 [==============================] - 1s 1ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "934/934 [==============================] - 1s 802us/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "934/934 [==============================] - 1s 790us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "934/934 [==============================] - 1s 813us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "934/934 [==============================] - 1s 856us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "934/934 [==============================] - 1s 769us/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "934/934 [==============================] - 1s 806us/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "934/934 [==============================] - 1s 871us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "934/934 [==============================] - 1s 851us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "934/934 [==============================] - 1s 771us/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "934/934 [==============================] - 1s 770us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "934/934 [==============================] - 1s 762us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "934/934 [==============================] - 1s 766us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "934/934 [==============================] - 1s 774us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "934/934 [==============================] - 1s 765us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "934/934 [==============================] - 1s 778us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "934/934 [==============================] - 1s 863us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "8\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 0s 766us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 874us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 794us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 809us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 810us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 779us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 852us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 898us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 959us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 992us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 785us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 780us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 801us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 916us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 835us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 941us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 831us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "9\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 0s 786us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 823us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 815us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 823us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 831us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 988us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 974us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 788us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 792us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 791us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 813us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 874us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "10\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 919us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 950us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 815us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 882us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 970us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 888us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 850us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 798us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 791us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 789us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 905us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 949us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 998us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "11\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0138 - accuracy: 0.7133\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0070 - accuracy: 0.7150\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0048 - accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 884us/step - loss: 0.0036 - accuracy: 0.9267\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 862us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 842us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 910us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 846us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 859us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 861us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 776us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 884us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 814us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 816us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 977us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 818us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "12\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 0s 801us/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 785us/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 774us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 818us/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 917us/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 799us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 900us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 839us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 952us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 799us/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 904us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 818us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 795us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 794us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 844us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 823us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 864us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 800us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "13\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0270 - accuracy: 0.5200\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 840us/step - loss: 0.0177 - accuracy: 0.5067\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0141 - accuracy: 0.4983\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 871us/step - loss: 0.0119 - accuracy: 0.5033\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 842us/step - loss: 0.0104 - accuracy: 0.5317\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0093 - accuracy: 0.5850\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0085 - accuracy: 0.6283\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 943us/step - loss: 0.0078 - accuracy: 0.6900\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0073 - accuracy: 0.7683\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 875us/step - loss: 0.0068 - accuracy: 0.7733\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 910us/step - loss: 0.0065 - accuracy: 0.7783\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 914us/step - loss: 0.0061 - accuracy: 0.7933\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 939us/step - loss: 0.0059 - accuracy: 0.7867\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 915us/step - loss: 0.0056 - accuracy: 0.7967\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 872us/step - loss: 0.0054 - accuracy: 0.8050\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 925us/step - loss: 0.0053 - accuracy: 0.8067\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 912us/step - loss: 0.0051 - accuracy: 0.8083\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 961us/step - loss: 0.0050 - accuracy: 0.8117\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 888us/step - loss: 0.0049 - accuracy: 0.8117\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 907us/step - loss: 0.0048 - accuracy: 0.8150\n",
      "14\n",
      "(1103, 1, 9)\n",
      "(1103, 1, 9)\n",
      "Epoch 1/20\n",
      "1103/1103 [==============================] - 1s 871us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "1103/1103 [==============================] - 1s 910us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "1103/1103 [==============================] - 1s 935us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "1103/1103 [==============================] - 1s 907us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "1103/1103 [==============================] - 1s 903us/step - loss: 9.8171e-04 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "1103/1103 [==============================] - 1s 871us/step - loss: 8.9538e-04 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "1103/1103 [==============================] - 1s 865us/step - loss: 8.2831e-04 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "1103/1103 [==============================] - 1s 885us/step - loss: 7.7397e-04 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "1103/1103 [==============================] - 1s 895us/step - loss: 7.3023e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "1103/1103 [==============================] - 1s 888us/step - loss: 6.9207e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "1103/1103 [==============================] - 1s 889us/step - loss: 6.5891e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "1103/1103 [==============================] - 1s 875us/step - loss: 6.3195e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "1103/1103 [==============================] - 1s 857us/step - loss: 6.0640e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "1103/1103 [==============================] - 1s 910us/step - loss: 5.8403e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "1103/1103 [==============================] - 1s 861us/step - loss: 5.6200e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "1103/1103 [==============================] - 1s 853us/step - loss: 5.4486e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1103/1103 [==============================] - 1s 910us/step - loss: 5.2576e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1103/1103 [==============================] - 1s 876us/step - loss: 5.1146e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1103/1103 [==============================] - 1s 853us/step - loss: 4.9711e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1103/1103 [==============================] - 1s 848us/step - loss: 4.8193e-04 - accuracy: 1.0000\n",
      "15\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 856us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 863us/step - loss: 7.7524e-04 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 902us/step - loss: 7.4336e-04 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 842us/step - loss: 7.1576e-04 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 842us/step - loss: 6.9017e-04 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 841us/step - loss: 6.6570e-04 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 866us/step - loss: 6.4669e-04 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 842us/step - loss: 6.2522e-04 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 846us/step - loss: 6.0791e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 889us/step - loss: 5.9024e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 907us/step - loss: 5.7751e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 887us/step - loss: 5.5968e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 852us/step - loss: 5.4856e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 838us/step - loss: 5.3507e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 842us/step - loss: 5.2321e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 907us/step - loss: 5.1034e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 834us/step - loss: 5.0103e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 857us/step - loss: 4.9182e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 861us/step - loss: 4.8106e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 4.7194e-04 - accuracy: 1.0000\n",
      "16\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 887us/step - loss: 5.2940e-04 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 963us/step - loss: 3.9482e-04 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 941us/step - loss: 3.7313e-04 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 937us/step - loss: 3.5542e-04 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 3.4082e-04 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 3.2793e-04 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 959us/step - loss: 3.1495e-04 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 3.0719e-04 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 860us/step - loss: 2.9991e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 943us/step - loss: 2.9313e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 961us/step - loss: 2.8603e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 2.8082e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 2.7525e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 979us/step - loss: 2.7025e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 903us/step - loss: 2.6654e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 864us/step - loss: 2.6222e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 912us/step - loss: 2.5758e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 2.5528e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 2.5138e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 2.4840e-04 - accuracy: 1.0000\n",
      "17\n",
      "(972, 1, 9)\n",
      "(972, 1, 9)\n",
      "Epoch 1/20\n",
      "972/972 [==============================] - 1s 1ms/step - loss: 0.0269 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "972/972 [==============================] - 1s 1ms/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "972/972 [==============================] - 1s 1ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "972/972 [==============================] - 1s 882us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "972/972 [==============================] - 1s 956us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "972/972 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "972/972 [==============================] - 1s 990us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "972/972 [==============================] - 1s 985us/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "972/972 [==============================] - 1s 902us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "972/972 [==============================] - 1s 985us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "972/972 [==============================] - 1s 948us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "972/972 [==============================] - 1s 1ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "972/972 [==============================] - 1s 972us/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "972/972 [==============================] - 1s 1ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "972/972 [==============================] - 1s 1ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "972/972 [==============================] - 1s 1ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "972/972 [==============================] - 1s 1ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "972/972 [==============================] - 1s 1ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "972/972 [==============================] - 1s 1ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "972/972 [==============================] - 1s 1ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "18\n",
      "(1078, 1, 9)\n",
      "(1078, 1, 9)\n",
      "Epoch 1/20\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0163 - accuracy: 0.9258\n",
      "Epoch 2/20\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0094 - accuracy: 0.9258\n",
      "Epoch 3/20\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0080 - accuracy: 0.9462\n",
      "Epoch 4/20\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0076 - accuracy: 0.9610\n",
      "Epoch 5/20\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0075 - accuracy: 0.9703\n",
      "Epoch 6/20\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.9722\n",
      "Epoch 7/20\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0073 - accuracy: 0.9750\n",
      "Epoch 8/20\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0073 - accuracy: 0.9768\n",
      "Epoch 9/20\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0072 - accuracy: 0.9787\n",
      "Epoch 10/20\n",
      "1078/1078 [==============================] - 1s 952us/step - loss: 0.0071 - accuracy: 0.9759\n",
      "Epoch 11/20\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0071 - accuracy: 0.9759\n",
      "Epoch 12/20\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0071 - accuracy: 0.9768\n",
      "Epoch 13/20\n",
      "1078/1078 [==============================] - 1s 894us/step - loss: 0.0070 - accuracy: 0.9768\n",
      "Epoch 14/20\n",
      "1078/1078 [==============================] - 1s 961us/step - loss: 0.0070 - accuracy: 0.9759\n",
      "Epoch 15/20\n",
      "1078/1078 [==============================] - 1s 927us/step - loss: 0.0069 - accuracy: 0.9759\n",
      "Epoch 16/20\n",
      "1078/1078 [==============================] - 1s 895us/step - loss: 0.0069 - accuracy: 0.9768\n",
      "Epoch 17/20\n",
      "1078/1078 [==============================] - 1s 895us/step - loss: 0.0068 - accuracy: 0.9768\n",
      "Epoch 18/20\n",
      "1078/1078 [==============================] - 1s 903us/step - loss: 0.0068 - accuracy: 0.9768\n",
      "Epoch 19/20\n",
      "1078/1078 [==============================] - 1s 910us/step - loss: 0.0068 - accuracy: 0.9750\n",
      "Epoch 20/20\n",
      "1078/1078 [==============================] - 1s 864us/step - loss: 0.0067 - accuracy: 0.9768\n",
      "19\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 894us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 870us/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 920us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 944us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 824us/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 862us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 921us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 932us/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 912us/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 902us/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 907us/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 944us/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 962us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 998us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 949us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 966us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "20\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0198 - accuracy: 0.8267\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0111 - accuracy: 0.8500\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0085 - accuracy: 0.9233\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.9600\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0070 - accuracy: 0.9667\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 834us/step - loss: 0.0068 - accuracy: 0.9650\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0067 - accuracy: 0.9667\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0066 - accuracy: 0.9650\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0066 - accuracy: 0.9650\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0065 - accuracy: 0.9683\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 960us/step - loss: 0.0065 - accuracy: 0.9667\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 908us/step - loss: 0.0065 - accuracy: 0.9650\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 894us/step - loss: 0.0065 - accuracy: 0.9650\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 975us/step - loss: 0.0064 - accuracy: 0.9667\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 931us/step - loss: 0.0064 - accuracy: 0.9667\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 844us/step - loss: 0.0064 - accuracy: 0.9650\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0064 - accuracy: 0.9667\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0064 - accuracy: 0.9667\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0064 - accuracy: 0.9650\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0063 - accuracy: 0.9683\n",
      "21\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 997us/step - loss: 0.0211 - accuracy: 0.7917\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 878us/step - loss: 0.0111 - accuracy: 0.8383\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 846us/step - loss: 0.0083 - accuracy: 0.9083\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 911us/step - loss: 0.0073 - accuracy: 0.9567\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 881us/step - loss: 0.0069 - accuracy: 0.9667\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 877us/step - loss: 0.0068 - accuracy: 0.9733\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 849us/step - loss: 0.0066 - accuracy: 0.9750\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 860us/step - loss: 0.0066 - accuracy: 0.9733\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 902us/step - loss: 0.0066 - accuracy: 0.9750\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 867us/step - loss: 0.0065 - accuracy: 0.9733\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 864us/step - loss: 0.0065 - accuracy: 0.9767\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 872us/step - loss: 0.0064 - accuracy: 0.9767\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 871us/step - loss: 0.0064 - accuracy: 0.9783\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 897us/step - loss: 0.0064 - accuracy: 0.9767\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 847us/step - loss: 0.0063 - accuracy: 0.9767\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 844us/step - loss: 0.0063 - accuracy: 0.9767\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 874us/step - loss: 0.0063 - accuracy: 0.9783\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 899us/step - loss: 0.0063 - accuracy: 0.9767\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 994us/step - loss: 0.0062 - accuracy: 0.9750\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 907us/step - loss: 0.0062 - accuracy: 0.9767\n",
      "22\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 852us/step - loss: 0.0161 - accuracy: 0.8317\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 862us/step - loss: 0.0122 - accuracy: 0.8300\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 914us/step - loss: 0.0115 - accuracy: 0.8233\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 861us/step - loss: 0.0110 - accuracy: 0.8200\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 855us/step - loss: 0.0106 - accuracy: 0.8300\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 876us/step - loss: 0.0102 - accuracy: 0.8333\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 876us/step - loss: 0.0099 - accuracy: 0.8350\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0096 - accuracy: 0.8383\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 909us/step - loss: 0.0093 - accuracy: 0.8383\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 882us/step - loss: 0.0091 - accuracy: 0.8383\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 967us/step - loss: 0.0089 - accuracy: 0.8400\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0087 - accuracy: 0.8400\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 923us/step - loss: 0.0085 - accuracy: 0.8417\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 896us/step - loss: 0.0084 - accuracy: 0.8417\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 940us/step - loss: 0.0082 - accuracy: 0.8417\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 919us/step - loss: 0.0081 - accuracy: 0.8433\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 862us/step - loss: 0.0080 - accuracy: 0.8467\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 852us/step - loss: 0.0079 - accuracy: 0.8550\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 868us/step - loss: 0.0078 - accuracy: 0.8533\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 861us/step - loss: 0.0077 - accuracy: 0.8583\n"
     ]
    }
   ],
   "source": [
    "#Fit list of datasets to model\n",
    "\n",
    "#training_x, training_y, model to train on, epoch count, batch size, ?verbose\n",
    "epochs, batch_size = FitToList(x, y, model_2, 20, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0863 - accuracy: 0.7708\n",
      "test loss, test acc: [0.08630823824485695, 0.7708260702830847]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = EvaluateModel(x_test, y_test, model_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape: (5400, 9)\n",
      "Actual Values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Waist_X</th>\n",
       "      <th>Waist_Y</th>\n",
       "      <th>Waist_Z</th>\n",
       "      <th>R_Foot_X</th>\n",
       "      <th>R_Foot_Y</th>\n",
       "      <th>R_Foot_Z</th>\n",
       "      <th>L_Foot_X</th>\n",
       "      <th>L_Foot_Y</th>\n",
       "      <th>L_Foot_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.060439</td>\n",
       "      <td>1.022620</td>\n",
       "      <td>-0.098646</td>\n",
       "      <td>0.296409</td>\n",
       "      <td>0.111177</td>\n",
       "      <td>-0.002579</td>\n",
       "      <td>-0.105350</td>\n",
       "      <td>0.107512</td>\n",
       "      <td>0.008089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.060260</td>\n",
       "      <td>1.022620</td>\n",
       "      <td>-0.098646</td>\n",
       "      <td>0.296409</td>\n",
       "      <td>0.111177</td>\n",
       "      <td>-0.002579</td>\n",
       "      <td>-0.105350</td>\n",
       "      <td>0.107512</td>\n",
       "      <td>0.008089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059955</td>\n",
       "      <td>1.022620</td>\n",
       "      <td>-0.098769</td>\n",
       "      <td>0.296418</td>\n",
       "      <td>0.111177</td>\n",
       "      <td>-0.002579</td>\n",
       "      <td>-0.105350</td>\n",
       "      <td>0.107433</td>\n",
       "      <td>0.008048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059620</td>\n",
       "      <td>1.022658</td>\n",
       "      <td>-0.099001</td>\n",
       "      <td>0.296458</td>\n",
       "      <td>0.111177</td>\n",
       "      <td>-0.002579</td>\n",
       "      <td>-0.105350</td>\n",
       "      <td>0.107417</td>\n",
       "      <td>0.007960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059283</td>\n",
       "      <td>1.022695</td>\n",
       "      <td>-0.099210</td>\n",
       "      <td>0.296351</td>\n",
       "      <td>0.111177</td>\n",
       "      <td>-0.002579</td>\n",
       "      <td>-0.105444</td>\n",
       "      <td>0.107411</td>\n",
       "      <td>0.007911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>-0.266650</td>\n",
       "      <td>1.028392</td>\n",
       "      <td>-0.104049</td>\n",
       "      <td>-0.055547</td>\n",
       "      <td>0.211484</td>\n",
       "      <td>0.045802</td>\n",
       "      <td>-0.325084</td>\n",
       "      <td>0.122200</td>\n",
       "      <td>0.065459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>-0.263761</td>\n",
       "      <td>1.024829</td>\n",
       "      <td>-0.101151</td>\n",
       "      <td>-0.055403</td>\n",
       "      <td>0.215707</td>\n",
       "      <td>0.044948</td>\n",
       "      <td>-0.325417</td>\n",
       "      <td>0.121903</td>\n",
       "      <td>0.065412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>-0.271885</td>\n",
       "      <td>1.032776</td>\n",
       "      <td>-0.107868</td>\n",
       "      <td>-0.054945</td>\n",
       "      <td>0.219580</td>\n",
       "      <td>0.044346</td>\n",
       "      <td>-0.325417</td>\n",
       "      <td>0.121905</td>\n",
       "      <td>0.065404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>-0.268666</td>\n",
       "      <td>1.028839</td>\n",
       "      <td>-0.104847</td>\n",
       "      <td>-0.054282</td>\n",
       "      <td>0.222948</td>\n",
       "      <td>0.044158</td>\n",
       "      <td>-0.325470</td>\n",
       "      <td>0.121905</td>\n",
       "      <td>0.065396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>-0.275608</td>\n",
       "      <td>1.036180</td>\n",
       "      <td>-0.110867</td>\n",
       "      <td>-0.053518</td>\n",
       "      <td>0.225989</td>\n",
       "      <td>0.044157</td>\n",
       "      <td>-0.325380</td>\n",
       "      <td>0.121905</td>\n",
       "      <td>0.065388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5400 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Waist_X   Waist_Y   Waist_Z  R_Foot_X  R_Foot_Y  R_Foot_Z  L_Foot_X  \\\n",
       "0     0.060439  1.022620 -0.098646  0.296409  0.111177 -0.002579 -0.105350   \n",
       "1     0.060260  1.022620 -0.098646  0.296409  0.111177 -0.002579 -0.105350   \n",
       "2     0.059955  1.022620 -0.098769  0.296418  0.111177 -0.002579 -0.105350   \n",
       "3     0.059620  1.022658 -0.099001  0.296458  0.111177 -0.002579 -0.105350   \n",
       "4     0.059283  1.022695 -0.099210  0.296351  0.111177 -0.002579 -0.105444   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5395 -0.266650  1.028392 -0.104049 -0.055547  0.211484  0.045802 -0.325084   \n",
       "5396 -0.263761  1.024829 -0.101151 -0.055403  0.215707  0.044948 -0.325417   \n",
       "5397 -0.271885  1.032776 -0.107868 -0.054945  0.219580  0.044346 -0.325417   \n",
       "5398 -0.268666  1.028839 -0.104847 -0.054282  0.222948  0.044158 -0.325470   \n",
       "5399 -0.275608  1.036180 -0.110867 -0.053518  0.225989  0.044157 -0.325380   \n",
       "\n",
       "      L_Foot_Y  L_Foot_Z  \n",
       "0     0.107512  0.008089  \n",
       "1     0.107512  0.008089  \n",
       "2     0.107433  0.008048  \n",
       "3     0.107417  0.007960  \n",
       "4     0.107411  0.007911  \n",
       "...        ...       ...  \n",
       "5395  0.122200  0.065459  \n",
       "5396  0.121903  0.065412  \n",
       "5397  0.121905  0.065404  \n",
       "5398  0.121905  0.065396  \n",
       "5399  0.121905  0.065388  \n",
       "\n",
       "[5400 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicited Values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Waist_X</th>\n",
       "      <th>Waist_Y</th>\n",
       "      <th>Waist_Z</th>\n",
       "      <th>R_Foot_X</th>\n",
       "      <th>R_Foot_Y</th>\n",
       "      <th>R_Foot_Z</th>\n",
       "      <th>L_Foot_X</th>\n",
       "      <th>L_Foot_Y</th>\n",
       "      <th>L_Foot_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045796</td>\n",
       "      <td>0.995048</td>\n",
       "      <td>-0.046811</td>\n",
       "      <td>0.156399</td>\n",
       "      <td>0.119529</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>-0.008249</td>\n",
       "      <td>0.139777</td>\n",
       "      <td>0.049285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045523</td>\n",
       "      <td>0.994901</td>\n",
       "      <td>-0.046653</td>\n",
       "      <td>0.156055</td>\n",
       "      <td>0.119601</td>\n",
       "      <td>0.007891</td>\n",
       "      <td>-0.008459</td>\n",
       "      <td>0.139713</td>\n",
       "      <td>0.049262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.045237</td>\n",
       "      <td>0.994714</td>\n",
       "      <td>-0.046491</td>\n",
       "      <td>0.155726</td>\n",
       "      <td>0.119664</td>\n",
       "      <td>0.007807</td>\n",
       "      <td>-0.008677</td>\n",
       "      <td>0.139650</td>\n",
       "      <td>0.049253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044929</td>\n",
       "      <td>0.994533</td>\n",
       "      <td>-0.046392</td>\n",
       "      <td>0.155415</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>-0.008936</td>\n",
       "      <td>0.139602</td>\n",
       "      <td>0.049196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.044505</td>\n",
       "      <td>0.994411</td>\n",
       "      <td>-0.046321</td>\n",
       "      <td>0.154952</td>\n",
       "      <td>0.119729</td>\n",
       "      <td>0.007614</td>\n",
       "      <td>-0.009329</td>\n",
       "      <td>0.139565</td>\n",
       "      <td>0.049123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>-0.216685</td>\n",
       "      <td>1.014766</td>\n",
       "      <td>-0.119630</td>\n",
       "      <td>-0.180516</td>\n",
       "      <td>0.136369</td>\n",
       "      <td>-0.074052</td>\n",
       "      <td>-0.271115</td>\n",
       "      <td>0.132533</td>\n",
       "      <td>-0.061018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>-0.216420</td>\n",
       "      <td>1.016081</td>\n",
       "      <td>-0.120537</td>\n",
       "      <td>-0.182189</td>\n",
       "      <td>0.137141</td>\n",
       "      <td>-0.075245</td>\n",
       "      <td>-0.270983</td>\n",
       "      <td>0.132110</td>\n",
       "      <td>-0.063776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>-0.216083</td>\n",
       "      <td>1.017301</td>\n",
       "      <td>-0.121268</td>\n",
       "      <td>-0.183811</td>\n",
       "      <td>0.137923</td>\n",
       "      <td>-0.076278</td>\n",
       "      <td>-0.270753</td>\n",
       "      <td>0.131686</td>\n",
       "      <td>-0.066311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>-0.215661</td>\n",
       "      <td>1.018524</td>\n",
       "      <td>-0.121838</td>\n",
       "      <td>-0.185240</td>\n",
       "      <td>0.138686</td>\n",
       "      <td>-0.077102</td>\n",
       "      <td>-0.270405</td>\n",
       "      <td>0.131278</td>\n",
       "      <td>-0.068514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>-0.215186</td>\n",
       "      <td>1.019838</td>\n",
       "      <td>-0.122393</td>\n",
       "      <td>-0.186555</td>\n",
       "      <td>0.139424</td>\n",
       "      <td>-0.077783</td>\n",
       "      <td>-0.270006</td>\n",
       "      <td>0.130908</td>\n",
       "      <td>-0.070489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5400 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Waist_X   Waist_Y   Waist_Z  R_Foot_X  R_Foot_Y  R_Foot_Z  L_Foot_X  \\\n",
       "0     0.045796  0.995048 -0.046811  0.156399  0.119529  0.007963 -0.008249   \n",
       "1     0.045523  0.994901 -0.046653  0.156055  0.119601  0.007891 -0.008459   \n",
       "2     0.045237  0.994714 -0.046491  0.155726  0.119664  0.007807 -0.008677   \n",
       "3     0.044929  0.994533 -0.046392  0.155415  0.119700  0.007692 -0.008936   \n",
       "4     0.044505  0.994411 -0.046321  0.154952  0.119729  0.007614 -0.009329   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5395 -0.216685  1.014766 -0.119630 -0.180516  0.136369 -0.074052 -0.271115   \n",
       "5396 -0.216420  1.016081 -0.120537 -0.182189  0.137141 -0.075245 -0.270983   \n",
       "5397 -0.216083  1.017301 -0.121268 -0.183811  0.137923 -0.076278 -0.270753   \n",
       "5398 -0.215661  1.018524 -0.121838 -0.185240  0.138686 -0.077102 -0.270405   \n",
       "5399 -0.215186  1.019838 -0.122393 -0.186555  0.139424 -0.077783 -0.270006   \n",
       "\n",
       "      L_Foot_Y  L_Foot_Z  \n",
       "0     0.139777  0.049285  \n",
       "1     0.139713  0.049262  \n",
       "2     0.139650  0.049253  \n",
       "3     0.139602  0.049196  \n",
       "4     0.139565  0.049123  \n",
       "...        ...       ...  \n",
       "5395  0.132533 -0.061018  \n",
       "5396  0.132110 -0.063776  \n",
       "5397  0.131686 -0.066311  \n",
       "5398  0.131278 -0.068514  \n",
       "5399  0.130908 -0.070489  \n",
       "\n",
       "[5400 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_values, actual_values = PredictModel(x_test, y_test, model_2)\n",
    "\n",
    "toWriteActual, toWritePred = DisplayPredictions(predicted_values, actual_values, 0, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Results to File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def WriteResultToFile(path, pred, actual, model, metrics, file_list, epochs, b_size):\n",
    "    try:\n",
    "        #get current date for folder naming\n",
    "        now = datetime.now()\n",
    "        dt_string = now.strftime(\"%d_%m_%Y_%H_%M\")\n",
    "    \n",
    "        #create new folder\n",
    "        new_folder = \"run_\" + dt_string\n",
    "        os.makedirs(path + new_folder)\n",
    "\n",
    "        #loop over columns to split between actual and predicted\n",
    "        for column in actual.columns:\n",
    "            new_column = \"A_\" + column\n",
    "            actual = actual.rename(columns={column : new_column})\n",
    "        for column in pred.columns:\n",
    "            new_column = \"P_\" + column\n",
    "            pred = pred.rename(columns={column : new_column})\n",
    "\n",
    "        #combine both actual and predicted dataframes\n",
    "        results = pd.concat([actual, pred], axis=1)\n",
    "    \n",
    "        #create output path for csv write\n",
    "        output_folder = results_path + new_folder\n",
    "        results.to_csv(output_folder + \"/prediction.csv\", index = False, float_format='%.6f')\n",
    "        metric_labels = [\"Loss: \", \"Accuracy: \"]    \n",
    "        compile_params_list = [\"Loss Function: \", \"Optimizer: \", \"Metrics: \"]\n",
    "        #create new txt file to output model and training data summary\n",
    "        with open(output_folder + '/summary.txt','w') as fh:\n",
    "            model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "            fh.write(\"Epochs: \")\n",
    "            fh.write(str(epochs) + \"\\n\")\n",
    "            fh.write(\"Batch Size: \")\n",
    "            fh.write(str(b_size) + \"\\n\")\n",
    "            fh.write(\"Metrics:\\n\")\n",
    "            for i in range (len(metrics)):\n",
    "                fh.write(metric_labels[i])\n",
    "                fh.write(str(metrics[i]) + \"\\n\")\n",
    "            fh.write(\"Trained On:\\n\")\n",
    "            for file in file_list:\n",
    "                fh.write(file + \"\\n\")\n",
    "            for i in range (len(compile_params)):\n",
    "                fh.write(compile_params_list[i])\n",
    "                fh.write(compile_params[i] + \"\\n\")\n",
    "        print(\"File Output to \" + new_folder)\n",
    "    except: \n",
    "        \n",
    "        print(\"Error Writing Results To File!\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Output to run_01_08_2022_00_35\n"
     ]
    }
   ],
   "source": [
    "results_path = \"../results/\"\n",
    "\n",
    "WriteResultToFile(results_path, toWritePred, toWriteActual, model_2, results, files, epochs, batch_size) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "85273928d8596bf28b6a3fc4ded2b0665eee93193e52c7eff13f3a9a291ee5c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data From CSV Recording\n",
    "\n",
    "## Load File\n",
    "\n",
    "Data is loaded from a CSV recording file, accepted through an input prompt. This includes all positional data related to the 6 trackers (HMD, Left Controller, Right Controller, Waist, Left Foot, Right Foot).\n",
    "\n",
    "'Data is loaded into a Pandas dataframe. The primary tracking data is then extracted, leaving extraneous data such as booleans for button presses.\n",
    "\n",
    "The extracted columns are then concatenated into a new dataframe, and the columns are renamed for ease of reading.\n",
    "\n",
    "The new trimmed file is written to a directory (/trim_output), for further manipulation and loading into the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input File Name walking_2_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Reading File: Check Spelling and Try Again\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 6 elements, new values have 18 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m joined \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([HMD, controller_1, controller_2,\n\u001b[0;32m     25\u001b[0m                    waist, left_foot, right_foot], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# set new column headers\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m joined\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead_x\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead_y\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead_z\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr_controller_x\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr_controller_y\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr_controller_z\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml_controller_x\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml_controller_y\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml_controller_z\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwaist_x\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwaist_y\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwaist_z\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr_foot_x\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr_foot_y\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr_foot_z\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml_foot_x\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml_foot_y\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml_foot_z\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     47\u001b[0m ]\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# output to new csv\u001b[39;00m\n\u001b[0;32m     51\u001b[0m output_file \u001b[38;5;241m=\u001b[39m output_path \u001b[38;5;241m+\u001b[39m file_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_trimmed.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:5588\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   5587\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 5588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   5590\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\properties.pyx:70\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:769\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: \u001b[38;5;28mint\u001b[39m, labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    768\u001b[0m     labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:214\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: \u001b[38;5;28mint\u001b[39m, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\base.py:69\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 6 elements, new values have 18 elements"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "recording_path = \"../recordings/\"\n",
    "output_path = \"../trim_output/\"\n",
    "file_name = input(\"Input File Name\")\n",
    "\n",
    "#Read in CSV\n",
    "\n",
    "try:\n",
    "    dataframe = pd.read_csv(recording_path + file_name + \".csv\")\n",
    "except:\n",
    "    print(\"Error Reading File: Check Spelling and Try Again\")\n",
    "\n",
    "# Seperate each tracker to seperate dataframe\n",
    "HMD = dataframe.iloc[:, 1:4]\n",
    "controller_1 = dataframe.iloc[:, 7:10]\n",
    "controller_2 = dataframe.iloc[:, 37:40]\n",
    "left_foot = dataframe.iloc[:, 67:70]\n",
    "right_foot = dataframe.iloc[:, 73:76]\n",
    "waist = dataframe.iloc[:, 79:82]\n",
    "\n",
    "# Join all trackers together\n",
    "joined = pd.concat([HMD, controller_1, controller_2,\n",
    "                   waist, left_foot, right_foot], axis=1)\n",
    "\n",
    "# set new column headers\n",
    "joined.columns = [\n",
    "    \"head_x\",\n",
    "    \"head_y\",\n",
    "    \"head_z\",\n",
    "    \"r_controller_x\",\n",
    "    \"r_controller_y\", \n",
    "    \"r_controller_z\",\n",
    "    \"l_controller_x\",\n",
    "    \"l_controller_y\",\n",
    "    \"l_controller_z\",\n",
    "    \"waist_x\",\n",
    "    \"waist_y\",\n",
    "    \"waist_z\",\n",
    "    \"r_foot_x\",\n",
    "    \"r_foot_y\",\n",
    "    \"r_foot_z\",\n",
    "    \"l_foot_x\",\n",
    "    \"l_foot_y\",\n",
    "    \"l_foot_z\"\n",
    "]\n",
    "\n",
    "\n",
    "# output to new csv\n",
    "output_file = output_path + file_name + \"_trimmed.csv\"\n",
    "joined.to_csv(output_file, index=False)\n",
    "\n",
    "print(file_name + \" output to \" + output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization\n",
    "\n",
    "## Data Scaling\n",
    "\n",
    "The new CSV is loaded into memory, chosen through an input prompt\n",
    "The data is then split between the features (the HMD and controller tracking data), and the labels (the waist and foot trackers).\n",
    "These are loaded into Numpy arrays to peform normaliztion. The output from OpenVR Recorder is upscaled by 100. To correct this the array is divided by 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "#import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "output_path = \"../trim_output/\"\n",
    "\n",
    "\n",
    "#read in formatted CSV\n",
    "def ReadCSV():\n",
    "    file_name = input(\"Input File Name\")\n",
    "    try:\n",
    "        dataframe = pd.read_csv(output_path + file_name + \".csv\")\n",
    "        print(\"Dataframe created\")\n",
    "    except:\n",
    "        print(\"Error Reading File\")\n",
    "    return dataframe\n",
    "\n",
    "def SplitFeaturesLabels(dataframe):\n",
    "    x = dataframe.iloc[:, 0:9]\n",
    "    y = dataframe.iloc[:, 9:18]\n",
    "    return x, y\n",
    "\n",
    "#Load data into Numpy array\n",
    "def LoadArray(x, y):\n",
    "    x_array = np.array(x)\n",
    "    y_array = np.array(y)\n",
    "    return x_array, y_array\n",
    "\n",
    "\n",
    "def NormalizeValues (x, y):\n",
    "    x =  np.divide(x, 100)\n",
    "    y =  np.divide(y, 100)\n",
    "    return x, y\n",
    "\n",
    "def SampleSize(x, y):\n",
    "    x_samples = x[0:900,:]\n",
    "    y_samples = y[0:900,:]\n",
    "    return x_samples, y_samples\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input File Name walking_1_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe created\n",
      "(900, 9) [[ 0.00396347  1.55321396 -0.09726781 ... -0.17044104  0.79216263\n",
      "  -0.12728346]\n",
      " [ 0.00396347  1.55321396 -0.0974095  ... -0.1698889   0.79222771\n",
      "  -0.12750142]\n",
      " [ 0.00419568  1.55321396 -0.09760312 ... -0.16916578  0.79246605\n",
      "  -0.12798414]\n",
      " ...\n",
      " [-0.02651245  1.59055893 -0.13678305 ... -0.11887306  0.75262321\n",
      "   0.13336996]\n",
      " [-0.03070768  1.59075287 -0.13581562 ... -0.13185926  0.75569618\n",
      "   0.13421907]\n",
      " [-0.03509516  1.5909549  -0.13504914 ... -0.14492013  0.75884453\n",
      "   0.13558317]]\n",
      "(900, 9) [[ 0.03550047  0.99325623 -0.06203985 ... -0.17026985  0.09899879\n",
      "   0.01698667]\n",
      " [ 0.03546809  0.99353798 -0.06230913 ... -0.17021811  0.09892341\n",
      "   0.01698667]\n",
      " [ 0.0358079   0.99352867 -0.06240509 ... -0.17014109  0.09882551\n",
      "   0.01698667]\n",
      " ...\n",
      " [-0.07211315  1.00282028 -0.1262004  ... -0.08610182  0.09165998\n",
      "   0.05806892]\n",
      " [-0.07784638  1.00439491 -0.1233117  ... -0.08573814  0.09138713\n",
      "   0.05814877]\n",
      " [-0.08183085  1.0055632  -0.12043599 ... -0.08560102  0.09083523\n",
      "   0.05812021]]\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "#load train data from csv\n",
    "train_dataframe = ReadCSV()\n",
    "\n",
    "#split features and labels into seperate dataframes\n",
    "x_train_df, y_train_df = SplitFeaturesLabels(train_dataframe)\n",
    "\n",
    "#convert features and labels to numpy array\n",
    "x_train, y_train = LoadArray(x_train_df, y_train_df)\n",
    "\n",
    "#Divide values in array by 100\n",
    "x_train_normalized, y_train_normalized = NormalizeValues(x_train, y_train)\n",
    "\n",
    "\n",
    "x_samples, y_samples = SampleSize(x_train_normalized, y_train_normalized)\n",
    "\n",
    "print(x_samples.shape, x_samples)\n",
    "print(y_samples.shape, y_samples)\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x_train_normalized, y_train_normalized)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ReshapeData(x, y):\n",
    "    x_reshaped = np.expand_dims(x, axis=1)\n",
    "    y_reshaped = np.expand_dims(y, axis=1)\n",
    "\n",
    "    return x_reshaped, y_reshaped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 1, 9) (900, 1, 9)\n",
      "1\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = ReshapeData(x_samples, y_samples)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "print(x_train.shape[1])\n",
    "\n",
    "print(x_train.shape[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test / Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input File Name walking_2_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe created\n",
      "(900, 1, 9) (900, 1, 9)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "test_dataframe = ReadCSV()\n",
    "\n",
    "#split features and labels into seperate dataframes\n",
    "x_test_df, y_test_df = SplitFeaturesLabels(test_dataframe)\n",
    "\n",
    "#convert features and labels to numpy array\n",
    "x_test, y_test = LoadArray(x_test_df, y_test_df)\n",
    "\n",
    "#Divide values in array by 100\n",
    "x_test_normalized, y_test_normalized = NormalizeValues(x_test, y_test)\n",
    "\n",
    "x_test_samples, y_test_samples = SampleSize(x_test_normalized, y_test_normalized)\n",
    "\n",
    "x_test, y_test = ReshapeData(x_test_samples, y_test_samples)\n",
    "\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "print(x_test.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"gru_15\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [74]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39madd(GRU(\u001b[38;5;241m9\u001b[39m,  input_shape\u001b[38;5;241m=\u001b[39m(x_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],x_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])))\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dropout(\u001b[38;5;241m0.2\u001b[39m))\n\u001b[1;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGRU\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dropout(\u001b[38;5;241m0.2\u001b[39m))\n\u001b[0;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m9\u001b[39m, activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:629\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 629\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py:214\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    212\u001b[0m   ndim \u001b[38;5;241m=\u001b[39m shape\u001b[38;5;241m.\u001b[39mrank\n\u001b[0;32m    213\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m!=\u001b[39m spec\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    215\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    216\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, found ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    217\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mmax_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    219\u001b[0m   ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"gru_15\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 9)"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(9, return_sequences=True, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(9, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(9, activation = \"relu\"))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "print ('model compiled')\n",
    "\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0818\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0815\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0816\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0816\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0815\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0814\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0815\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0815\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0818\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0815\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0813\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0813\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0814\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0813\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0814\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0812\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0811\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0813\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0809\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x262b7ad6bf0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(x_train, y_train, epochs=20,batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10086438182327483"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape: (900, 9)\n",
      "[[0.         0.9810058  0.14005643 ... 0.         0.11163873 0.15246763]\n",
      " [0.         0.98096037 0.14006484 ... 0.         0.11164343 0.15248524]\n",
      " [0.         0.98087372 0.14007096 ... 0.         0.11164781 0.1525026 ]\n",
      " ...\n",
      " [0.         0.96768579 0.13832566 ... 0.         0.1097853  0.15221212]\n",
      " [0.         0.96873128 0.1384157  ... 0.         0.10981201 0.15215462]\n",
      " [0.         0.96962389 0.13848058 ... 0.         0.10982646 0.15209785]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.981006</td>\n",
       "      <td>0.140056</td>\n",
       "      <td>0.077319</td>\n",
       "      <td>0.117531</td>\n",
       "      <td>0.146038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111639</td>\n",
       "      <td>0.152468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.980960</td>\n",
       "      <td>0.140065</td>\n",
       "      <td>0.077290</td>\n",
       "      <td>0.117536</td>\n",
       "      <td>0.146038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111643</td>\n",
       "      <td>0.152485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.980874</td>\n",
       "      <td>0.140071</td>\n",
       "      <td>0.077259</td>\n",
       "      <td>0.117538</td>\n",
       "      <td>0.146039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111648</td>\n",
       "      <td>0.152503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.980776</td>\n",
       "      <td>0.140080</td>\n",
       "      <td>0.077220</td>\n",
       "      <td>0.117540</td>\n",
       "      <td>0.146038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111654</td>\n",
       "      <td>0.152524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.980627</td>\n",
       "      <td>0.140085</td>\n",
       "      <td>0.077181</td>\n",
       "      <td>0.117539</td>\n",
       "      <td>0.146039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111661</td>\n",
       "      <td>0.152546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966955</td>\n",
       "      <td>0.138310</td>\n",
       "      <td>0.082910</td>\n",
       "      <td>0.114795</td>\n",
       "      <td>0.151546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109780</td>\n",
       "      <td>0.152388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.967293</td>\n",
       "      <td>0.138316</td>\n",
       "      <td>0.082948</td>\n",
       "      <td>0.114789</td>\n",
       "      <td>0.151433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109783</td>\n",
       "      <td>0.152299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.967686</td>\n",
       "      <td>0.138326</td>\n",
       "      <td>0.082994</td>\n",
       "      <td>0.114788</td>\n",
       "      <td>0.151322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109785</td>\n",
       "      <td>0.152212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.968731</td>\n",
       "      <td>0.138416</td>\n",
       "      <td>0.083001</td>\n",
       "      <td>0.114817</td>\n",
       "      <td>0.151169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109812</td>\n",
       "      <td>0.152155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.969624</td>\n",
       "      <td>0.138481</td>\n",
       "      <td>0.083046</td>\n",
       "      <td>0.114851</td>\n",
       "      <td>0.151044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109826</td>\n",
       "      <td>0.152098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5    6         7  \\\n",
       "0    0.0  0.981006  0.140056  0.077319  0.117531  0.146038  0.0  0.111639   \n",
       "1    0.0  0.980960  0.140065  0.077290  0.117536  0.146038  0.0  0.111643   \n",
       "2    0.0  0.980874  0.140071  0.077259  0.117538  0.146039  0.0  0.111648   \n",
       "3    0.0  0.980776  0.140080  0.077220  0.117540  0.146038  0.0  0.111654   \n",
       "4    0.0  0.980627  0.140085  0.077181  0.117539  0.146039  0.0  0.111661   \n",
       "..   ...       ...       ...       ...       ...       ...  ...       ...   \n",
       "895  0.0  0.966955  0.138310  0.082910  0.114795  0.151546  0.0  0.109780   \n",
       "896  0.0  0.967293  0.138316  0.082948  0.114789  0.151433  0.0  0.109783   \n",
       "897  0.0  0.967686  0.138326  0.082994  0.114788  0.151322  0.0  0.109785   \n",
       "898  0.0  0.968731  0.138416  0.083001  0.114817  0.151169  0.0  0.109812   \n",
       "899  0.0  0.969624  0.138481  0.083046  0.114851  0.151044  0.0  0.109826   \n",
       "\n",
       "            8  \n",
       "0    0.152468  \n",
       "1    0.152485  \n",
       "2    0.152503  \n",
       "3    0.152524  \n",
       "4    0.152546  \n",
       "..        ...  \n",
       "895  0.152388  \n",
       "896  0.152299  \n",
       "897  0.152212  \n",
       "898  0.152155  \n",
       "899  0.152098  \n",
       "\n",
       "[900 rows x 9 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "print(predictions)\n",
    "pd.DataFrame(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "85eeaad1f84315a0c9c5600e08c8d22c182ff5487c2ae8eda931033c2f461801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data From CSV Recording\n",
    "\n",
    "## Load File\n",
    "\n",
    "Data is loaded from a CSV recording file, accepted through an input prompt. This includes all positional data related to the 6 trackers (HMD, Left Controller, Right Controller, Waist, Left Foot, Right Foot).\n",
    "\n",
    "'Data is loaded into a Pandas dataframe. The primary tracking data is then extracted, leaving extraneous data such as booleans for button presses.\n",
    "\n",
    "The extracted columns are then concatenated into a new dataframe, and the columns are renamed for ease of reading.\n",
    "\n",
    "The new trimmed file is written to a directory (/trim_output), for further manipulation and loading into the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input File Name walking_2_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Reading File: Check Spelling and Try Again\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 6 elements, new values have 18 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m joined \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([HMD, controller_1, controller_2,\n\u001b[0;32m     25\u001b[0m                    waist, left_foot, right_foot], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# set new column headers\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m joined\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead_x\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead_y\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead_z\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr_controller_x\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr_controller_y\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr_controller_z\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml_controller_x\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml_controller_y\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml_controller_z\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwaist_x\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwaist_y\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwaist_z\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr_foot_x\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr_foot_y\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr_foot_z\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml_foot_x\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml_foot_y\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml_foot_z\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     47\u001b[0m ]\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# output to new csv\u001b[39;00m\n\u001b[0;32m     51\u001b[0m output_file \u001b[38;5;241m=\u001b[39m output_path \u001b[38;5;241m+\u001b[39m file_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_trimmed.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:5588\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   5587\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 5588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   5590\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\properties.pyx:70\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:769\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: \u001b[38;5;28mint\u001b[39m, labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    768\u001b[0m     labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:214\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: \u001b[38;5;28mint\u001b[39m, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\base.py:69\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 6 elements, new values have 18 elements"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "recording_path = \"../recordings/\"\n",
    "output_path = \"../trim_output/\"\n",
    "file_name = input(\"Input File Name\")\n",
    "\n",
    "#Read in CSV\n",
    "\n",
    "try:\n",
    "    dataframe = pd.read_csv(recording_path + file_name + \".csv\")\n",
    "except:\n",
    "    print(\"Error Reading File: Check Spelling and Try Again\")\n",
    "\n",
    "# Seperate each tracker to seperate dataframe\n",
    "HMD = dataframe.iloc[:, 1:4]\n",
    "controller_1 = dataframe.iloc[:, 7:10]\n",
    "controller_2 = dataframe.iloc[:, 37:40]\n",
    "left_foot = dataframe.iloc[:, 67:70]\n",
    "right_foot = dataframe.iloc[:, 73:76]\n",
    "waist = dataframe.iloc[:, 79:82]\n",
    "\n",
    "# Join all trackers together\n",
    "joined = pd.concat([HMD, controller_1, controller_2,\n",
    "                   waist, left_foot, right_foot], axis=1)\n",
    "\n",
    "# set new column headers\n",
    "joined.columns = [\n",
    "    \"head_x\",\n",
    "    \"head_y\",\n",
    "    \"head_z\",\n",
    "    \"r_controller_x\",\n",
    "    \"r_controller_y\", \n",
    "    \"r_controller_z\",\n",
    "    \"l_controller_x\",\n",
    "    \"l_controller_y\",\n",
    "    \"l_controller_z\",\n",
    "    \"waist_x\",\n",
    "    \"waist_y\",\n",
    "    \"waist_z\",\n",
    "    \"r_foot_x\",\n",
    "    \"r_foot_y\",\n",
    "    \"r_foot_z\",\n",
    "    \"l_foot_x\",\n",
    "    \"l_foot_y\",\n",
    "    \"l_foot_z\"\n",
    "]\n",
    "\n",
    "\n",
    "# output to new csv\n",
    "output_file = output_path + file_name + \"_trimmed.csv\"\n",
    "joined.to_csv(output_file, index=False)\n",
    "\n",
    "print(file_name + \" output to \" + output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization\n",
    "\n",
    "## Data Scaling\n",
    "\n",
    "The new CSV is loaded into memory, chosen through an input prompt\n",
    "The data is then split between the features (the HMD and controller tracking data), and the labels (the waist and foot trackers).\n",
    "These are loaded into Numpy arrays to peform normaliztion. The output from OpenVR Recorder is upscaled by 100. To correct this the array is divided by 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input File Name walking_1_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe created\n",
      "(972, 9) [[ 0.00396347  1.55321396 -0.09726781 ... -0.17044104  0.79216263\n",
      "  -0.12728346]\n",
      " [ 0.00396347  1.55321396 -0.0974095  ... -0.1698889   0.79222771\n",
      "  -0.12750142]\n",
      " [ 0.00419568  1.55321396 -0.09760312 ... -0.16916578  0.79246605\n",
      "  -0.12798414]\n",
      " ...\n",
      " [-0.07326494  1.57561111 -0.15563388 ... -0.28583529  0.76833069\n",
      "   0.04462518]\n",
      " [-0.07258665  1.57578445 -0.15483627 ... -0.28606691  0.76840103\n",
      "   0.04523792]\n",
      " [-0.07203475  1.57610062 -0.15404955 ... -0.28627296  0.76849533\n",
      "   0.04572279]]\n",
      "(972, 9) [[ 0.03550047  0.99325623 -0.06203985 ... -0.17026985  0.09899879\n",
      "   0.01698667]\n",
      " [ 0.03546809  0.99353798 -0.06230913 ... -0.17021811  0.09892341\n",
      "   0.01698667]\n",
      " [ 0.0358079   0.99352867 -0.06240509 ... -0.17014109  0.09882551\n",
      "   0.01698667]\n",
      " ...\n",
      " [-0.13245131  1.00056854 -0.13201273 ... -0.08991505  0.09783401\n",
      "   0.05129308]\n",
      " [-0.13226092  1.00068802 -0.13195515 ... -0.09031304  0.09860064\n",
      "   0.05091204]\n",
      " [-0.13171673  1.00074806 -0.13161671 ... -0.08997025  0.09833285\n",
      "   0.05118186]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "#import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "output_path = \"../trim_output/\"\n",
    "\n",
    "\n",
    "#read in formatted CSV\n",
    "def ReadCSV():\n",
    "    file_name = input(\"Input File Name\")\n",
    "    try:\n",
    "        dataframe = pd.read_csv(output_path + file_name + \".csv\")\n",
    "        print(\"Dataframe created\")\n",
    "    except:\n",
    "        print(\"Error Reading File\")\n",
    "    return dataframe\n",
    "\n",
    "def SplitFeaturesLabels(dataframe):\n",
    "    x = dataframe.iloc[:, 0:9]\n",
    "    y = dataframe.iloc[:, 9:18]\n",
    "    return x, y\n",
    "\n",
    "#Load data into Numpy array\n",
    "def LoadArray(x, y):\n",
    "    x_array = np.array(x)\n",
    "    y_array = np.array(y)\n",
    "    return x_array, y_array\n",
    "\n",
    "\n",
    "def NormalizeValues (x, y):\n",
    "    x =  np.divide(x, 100)\n",
    "    y =  np.divide(y, 100)\n",
    "    return x, y\n",
    "    \n",
    "#load train data from csv\n",
    "train_dataframe = ReadCSV()\n",
    "\n",
    "#split features and labels into seperate dataframes\n",
    "x_train_df, y_train_df = SplitFeaturesLabels(train_dataframe)\n",
    "\n",
    "#convert features and labels to numpy array\n",
    "x_train, y_train = LoadArray(x_train_df, y_train_df)\n",
    "\n",
    "#Divide values in array by 100\n",
    "x_train_normalized, y_train_normalized = NormalizeValues(x_train, y_train)\n",
    "\n",
    "\n",
    "print(x_train_normalized.shape, x_train_normalized)\n",
    "print(y_train_normalized.shape, y_train_normalized)\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x_train_normalized, y_train_normalized)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Reshape Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 972, 9) (1, 972, 9)\n",
      "972\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def ReshapeData(x, y):\n",
    "    x_reshaped = np.expand_dims(x, axis=0)\n",
    "    y_reshaped = np.expand_dims(y, axis=0)\n",
    "\n",
    "    return x_reshaped, y_reshaped\n",
    "\n",
    "x_train, y_train = ReshapeData(x_train_normalized, y_train_normalized)\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "print(x.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test / Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input File Name leg_raise_1_trimmed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe created\n",
      "(1, 934, 9) (1, 934, 9)\n",
      "934\n"
     ]
    }
   ],
   "source": [
    "test_dataframe = ReadCSV()\n",
    "\n",
    "#split features and labels into seperate dataframes\n",
    "x_test_df, y_test_df = SplitFeaturesLabels(test_dataframe)\n",
    "\n",
    "#convert features and labels to numpy array\n",
    "x_test, y_test = LoadArray(x_test_df, y_test_df)\n",
    "\n",
    "#Divide values in array by 100\n",
    "x_test_normalized, y_test_normalized = NormalizeValues(x_test, y_test)\n",
    "\n",
    "x_test, y_test = ReshapeData(x_test_normalized, y_test_normalized)\n",
    "\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "print(x_test.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (2992828403.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [91]\u001b[1;36m\u001b[0m\n\u001b[1;33m    model.add(GRU(50, return_sequences=True, input_shape= 1,9))\u001b[0m\n\u001b[1;37m                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "import tensorflow as tf\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "sample_size = 900\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(50, return_sequences=True, input_shape=( x_train.shape[1],9)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(9, activation = \"linear\"))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "print ('model compiled')\n",
    "\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.2298\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 0.1910\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 0.1292\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 0.1119\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.0991\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 0.0808\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 0.0817\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 0.1381\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 0.0967\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 0.0849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24bf0528eb0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(x_train, y_train, epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.046823158860206604"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape: (1, 9)\n",
      "[[ 0.09886805  1.2699304   0.14492653  0.06243226  0.2156406   0.1513913\n",
      "  -0.02488775  0.10999709  0.2702046 ]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test[:1])\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.05007839  0.96872963 -0.08983564 ... -0.20108604  0.09873713\n",
      "    0.0079338 ]\n",
      "  [-0.05154325  0.96869446 -0.08982277 ... -0.20106285  0.09862671\n",
      "    0.00806522]\n",
      "  [-0.05255925  0.96813133 -0.08953271 ... -0.20101883  0.09852489\n",
      "    0.00809575]\n",
      "  ...\n",
      "  [-0.01290206  0.970709   -0.09211598 ... -0.27577333  0.10105047\n",
      "    0.03015813]\n",
      "  [-0.01359766  0.97089333 -0.09273398 ... -0.27586189  0.10091614\n",
      "    0.0301379 ]\n",
      "  [-0.01392882  0.97103516 -0.09331501 ... -0.27587702  0.10096085\n",
      "    0.0301379 ]]]\n",
      "(1, 934, 9)\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:4])\n",
    "print(y_test[:4].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "85eeaad1f84315a0c9c5600e08c8d22c182ff5487c2ae8eda931033c2f461801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

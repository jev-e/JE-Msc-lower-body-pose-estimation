{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data From CSV Recording\n",
    "\n",
    "## Load File\n",
    "\n",
    "Data is loaded from a CSV recording file, accepted through an input prompt. This includes all positional data related to the 6 trackers (HMD, Left Controller, Right Controller, Waist, Left Foot, Right Foot).\n",
    "\n",
    "'Data is loaded into a Pandas dataframe. The primary tracking data is then extracted, leaving extraneous data such as booleans for button presses.\n",
    "\n",
    "The extracted columns are then concatenated into a new dataframe, and the columns are renamed for ease of reading.\n",
    "\n",
    "The columns are reorded in the order of head/r_controller/l_controller/waist/r_foot/l_foot.\n",
    "\n",
    "The new trimmed file is written to a directory (/test_data or /train_data), for further manipulation and loading into the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Read in CSV\n",
    "def GetRecording(path):\n",
    "    recording_path = \"../recordings/\"\n",
    "    file_name = input(\"Input Recording File Name\")\n",
    "    try:\n",
    "        dataframe = pd.read_csv(recording_path + file_name + \".csv\")\n",
    "        return dataframe, file_name\n",
    "    except: \n",
    "        print(\"Error Reading File: Check Spelling and Try Again\")\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "#Seperate each tracker to seperate dataframe\n",
    "\n",
    "def GetColByName(dataframe):\n",
    "    HMD = dataframe.loc[:, [\"HMD0_tx\", \"HMD0_ty\", \"HMD0_tz\"]]\n",
    "    \n",
    "    controller_1 = dataframe.loc[:, ['controller3_tx', 'controller3_ty', 'controller3_tz']]\n",
    "\n",
    "    controller_2 = dataframe.loc[:, ['controller4_tx', 'controller4_ty', 'controller4_tz']]\n",
    "\n",
    "    tracker_1 = dataframe.loc[:, ['generic7_tx', 'generic7_ty', 'generic7_tz']]\n",
    "\n",
    "    tracker_2 = dataframe.loc[:, ['generic8_tx', 'generic8_ty', 'generic8_tz']]\n",
    "\n",
    "    tracker_3 = dataframe.loc[:, ['generic9_tx', 'generic9_ty', 'generic9_tz']]\n",
    "\n",
    "    joined = pd.concat([HMD,controller_1, controller_2, tracker_1 ,tracker_2 ,tracker_3], axis=1)\n",
    "    return joined\n",
    "\n",
    "def AssignTracker(dataframe):\n",
    "    display(dataframe.iloc[0:1,:])\n",
    "    trackerNum = input('Input Tracker Number\")\n",
    "    for x in range(3):\n",
    "        trackerStr = str(trackerNum)\n",
    "        tracker = input('assign generic' + trackerStr)\n",
    "        dataframe.rename(columns={'generic' + trackerStr + '_tx': tracker + '_x', 'generic' + trackerStr + '_ty': tracker + \"_y\", 'generic' + trackerStr + '_tz': tracker + '_z'}, inplace=True)\n",
    "        trackerNum += 1\n",
    "        \n",
    "    controllerNum = 3\n",
    "    for x in range(2):\n",
    "        controllerStr = str(controllerNum)\n",
    "        controller = input('assign controller' + controllerStr)\n",
    "        dataframe.rename(columns={'controller' + controllerStr + '_tx': controller + '_x', 'controller' + controllerStr + '_ty': controller + \"_y\", 'controller' + controllerStr + '_tz': controller + '_z'}, inplace=True)\n",
    "        controllerNum += 1\n",
    "    dataframe.rename(columns={'HMD0_tx': 'head_x', 'HMD0_ty': 'head_y', 'HMD0_tz': 'head_z'}, inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "def GetDirectory():\n",
    "    choice = input(\"train or test data:\")\n",
    "    if choice == \"test\":\n",
    "        output_path = \"../test_data/\"\n",
    "    else:\n",
    "        output_path = \"../train_data/\"\n",
    "    return output_path\n",
    "\n",
    "def OrderFeatures(dataframe):\n",
    "    head = dataframe.loc[:, ['head_x', 'head_y', 'head_z']]\n",
    "    l_controller = dataframe.loc[:, ['l_controller_x', 'l_controller_y', 'l_controller_z']]\n",
    "    r_controller = dataframe.loc[:, ['r_controller_x', 'r_controller_y', 'r_controller_z']]\n",
    "    waist = dataframe.loc[:, ['waist_x', 'waist_y', 'waist_z']]\n",
    "    r_foot = dataframe.loc[:, ['r_foot_x', 'r_foot_y', 'r_foot_z']]\n",
    "    l_foot = dataframe.loc[:, ['l_foot_x', 'l_foot_y', 'l_foot_z']]\n",
    "    reordered = pd.concat([head , r_controller, l_controller, waist, r_foot, l_foot], axis=1)\n",
    "    return reordered\n",
    "\n",
    "    \n",
    "    \n",
    "def WriteOutput(path, dataframe, filename):\n",
    "    output_file = path + filename + \"_trimmed.csv\"\n",
    "    dataframe.to_csv(output_file, index = False)\n",
    "    print(file_name + \" output to \" + path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run data trimming functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Recording File Name leg_raise_5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HMD0_tx</th>\n",
       "      <th>HMD0_ty</th>\n",
       "      <th>HMD0_tz</th>\n",
       "      <th>controller3_tx</th>\n",
       "      <th>controller3_ty</th>\n",
       "      <th>controller3_tz</th>\n",
       "      <th>controller4_tx</th>\n",
       "      <th>controller4_ty</th>\n",
       "      <th>controller4_tz</th>\n",
       "      <th>generic7_tx</th>\n",
       "      <th>generic7_ty</th>\n",
       "      <th>generic7_tz</th>\n",
       "      <th>generic8_tx</th>\n",
       "      <th>generic8_ty</th>\n",
       "      <th>generic8_tz</th>\n",
       "      <th>generic9_tx</th>\n",
       "      <th>generic9_ty</th>\n",
       "      <th>generic9_tz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.964998</td>\n",
       "      <td>158.131058</td>\n",
       "      <td>3.838474</td>\n",
       "      <td>-18.907917</td>\n",
       "      <td>92.860924</td>\n",
       "      <td>-9.813828</td>\n",
       "      <td>29.159588</td>\n",
       "      <td>80.373276</td>\n",
       "      <td>2.166218</td>\n",
       "      <td>3.899813</td>\n",
       "      <td>97.88607</td>\n",
       "      <td>6.474656</td>\n",
       "      <td>21.754217</td>\n",
       "      <td>11.036432</td>\n",
       "      <td>13.468838</td>\n",
       "      <td>-12.954676</td>\n",
       "      <td>11.488569</td>\n",
       "      <td>19.045788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HMD0_tx     HMD0_ty   HMD0_tz  controller3_tx  controller3_ty  \\\n",
       "0  1.964998  158.131058  3.838474      -18.907917       92.860924   \n",
       "\n",
       "   controller3_tz  controller4_tx  controller4_ty  controller4_tz  \\\n",
       "0       -9.813828       29.159588       80.373276        2.166218   \n",
       "\n",
       "   generic7_tx  generic7_ty  generic7_tz  generic8_tx  generic8_ty  \\\n",
       "0     3.899813     97.88607     6.474656    21.754217    11.036432   \n",
       "\n",
       "   generic8_tz  generic9_tx  generic9_ty  generic9_tz  \n",
       "0    13.468838   -12.954676    11.488569    19.045788  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assign generic7 waist\n",
      "assign generic8 r_foot\n",
      "assign generic9 l_foot\n",
      "assign controller3 l_controller\n",
      "assign controller4 r_controller\n",
      "train or test data: test\n",
      "leg_raise_5 output to ../test_data/\n"
     ]
    }
   ],
   "source": [
    "recording_path = \" ../recordings\"\n",
    "\n",
    "dataframe, file_name = GetRecording(recording_path)\n",
    "joined = GetColByName(dataframe)\n",
    "renamed = AssignTracker(joined)\n",
    "path = GetDirectory()\n",
    "reordered = OrderFeatures(renamed)\n",
    "WriteOutput(path, reordered, file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalization\n",
    "\n",
    "## Data Scaling\n",
    "\n",
    "The new CSV is loaded into memory, chosen through an input prompt\n",
    "The data is then split between the features (the HMD and controller tracking data), and the labels (the waist and foot trackers).\n",
    "These are loaded into Numpy arrays to peform normaliztion. The output from OpenVR Recorder is upscaled by 100. To correct this the array is divided by 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "#import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "output_path = \"../trim_output/\"\n",
    "\n",
    "\n",
    "#read in formatted CSV\n",
    "def ReadCSV(path):\n",
    "    file_name = input(\"Input File Name\")\n",
    "    file_list = []\n",
    "    file_list.append(file_name)\n",
    "    try:\n",
    "        dataframe = pd.read_csv(path + file_name + \".csv\")\n",
    "        print(\"Dataframe created\")\n",
    "    except:\n",
    "        print(\"Error Reading File\")\n",
    "    return dataframe, file_list\n",
    "\n",
    "def SplitFeaturesLabels(dataframe):\n",
    "    x = dataframe.iloc[:, 0:9]\n",
    "    y = dataframe.iloc[:, 9:18]\n",
    "    return x, y\n",
    "\n",
    "#Load data into Numpy array\n",
    "def LoadArray(x, y):\n",
    "    x_array = np.array(x)\n",
    "    y_array = np.array(y)\n",
    "    return x_array, y_array\n",
    "\n",
    "\n",
    "def NormalizeValues (x, y):\n",
    "    x =  np.divide(x, 100)\n",
    "    y =  np.divide(y, 100)\n",
    "    return x, y\n",
    "\n",
    "def SampleSize(x, y):\n",
    "    x_samples = x[0:600,:]\n",
    "    y_samples = y[0:600,:]\n",
    "    return x_samples, y_samples\n",
    "\n",
    "def RoundValues(x, y): \n",
    "    x_rounded = np.around(x, 3)\n",
    "    y_rounded = np.around(y, 3)\n",
    "    return x_rounded, y_rounded\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input File Name walking_7_trimmed\n",
      "Dataframe created\n",
      "['walking_7_trimmed']\n",
      "(600, 9) [[0.56456936 1.65256363 0.82371849 ... 0.35004543 0.81725983 0.93927994]\n",
      " [0.56244183 1.6511261  0.82760582 ... 0.35082798 0.81521797 0.94517693]\n",
      " [0.56021255 1.64923187 0.8309227  ... 0.3510099  0.81342445 0.95069672]\n",
      " ...\n",
      " [0.42225151 1.55701126 0.6327589  ... 0.21533564 0.75101753 0.71076973]\n",
      " [0.41390022 1.55681183 0.62624306 ... 0.20336998 0.75672852 0.69413803]\n",
      " [0.40570499 1.55652176 0.6195657  ... 0.19236187 0.76251534 0.67823952]]\n",
      "(600, 9) [[0.56388847 0.9584938  0.82307373 ... 0.6701664  0.12568272 1.02205978]\n",
      " [0.5649939  0.95908966 0.8268927  ... 0.67017311 0.12555384 1.02190422]\n",
      " [0.5658884  0.95991432 0.83057884 ... 0.67164154 0.12405634 1.02306038]\n",
      " ...\n",
      " [0.4459425  0.94995354 0.64034004 ... 0.39146503 0.11636929 0.66756081]\n",
      " [0.43529736 0.9514679  0.63556534 ... 0.39199577 0.115468   0.66869583]\n",
      " [0.42703381 0.95304367 0.63249866 ... 0.39176373 0.11532265 0.66892319]]\n"
     ]
    }
   ],
   "source": [
    "train_path = \"../train_data/\"\n",
    "#load train data from csv\n",
    "train_dataframe, files = ReadCSV(train_path)\n",
    "\n",
    "print(files)\n",
    "#split features and labels into seperate dataframes\n",
    "x_train_df, y_train_df = SplitFeaturesLabels(train_dataframe)\n",
    "\n",
    "#convert features and labels to numpy array\n",
    "x_train, y_train = LoadArray(x_train_df, y_train_df)\n",
    "\n",
    "#Divide values in array by 100\n",
    "x_samples, y_samples = NormalizeValues(x_train, y_train)\n",
    "\n",
    "print(x_samples.shape, x_samples)\n",
    "print(y_samples.shape, y_samples)\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x_train_normalized, y_train_normalized)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(x_samples.max())\n",
    "print(x_samples.min())\n",
    "\n",
    "print(y_samples.max())\n",
    "print(y_samples.min())\n",
    "\n",
    "scaler =MinMaxScaler()\n",
    "print(x_samples[0:1])\n",
    "scaled = scaler.fit(x_samples)\n",
    "print(scaler.transform(x_samples[0:1]))\n",
    "print(scaler.inverse_transform(x_samples[0:1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ReshapeData(x, y):\n",
    "    x_reshaped = np.expand_dims(x, axis=1)\n",
    "    y_reshaped = np.expand_dims(y, axis=1)\n",
    "\n",
    "    return x_reshaped, y_reshaped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 1, 9) (600, 1, 9)\n",
      "1\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "x, y = ReshapeData(x_samples, y_samples)\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "print(x.shape[1])\n",
    "\n",
    "print(x.shape[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test / Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input File Name walking_7_trimmed\n",
      "Error Reading File\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'dataframe' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [67]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Create a single test data file\u001b[39;00m\n\u001b[0;32m      3\u001b[0m test_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../test_data/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m test_dataframe \u001b[38;5;241m=\u001b[39m \u001b[43mReadCSV\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#split features and labels into seperate dataframes\u001b[39;00m\n\u001b[0;32m      9\u001b[0m x_test_df, y_test_df \u001b[38;5;241m=\u001b[39m SplitFeaturesLabels(test_dataframe)\n",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36mReadCSV\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError Reading File\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataframe\u001b[49m, file_name\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'dataframe' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#Create a single test data file\n",
    "\n",
    "test_path = \"../test_data/\"\n",
    "\n",
    "\n",
    "test_dataframe = ReadCSV(test_path)\n",
    "\n",
    "#split features and labels into seperate dataframes\n",
    "x_test_df, y_test_df = SplitFeaturesLabels(test_dataframe)\n",
    "\n",
    "#convert features and labels to numpy array\n",
    "x_test, y_test = LoadArray(x_test_df, y_test_df)\n",
    "\n",
    "#Divide values in array by 100\n",
    "x_test_normalized, y_test_normalized = NormalizeValues(x_test, y_test)\n",
    "\n",
    "x_test_samples, y_test_samples = SampleSize(x_test_normalized, y_test_normalized)\n",
    "\n",
    "x, y = ReshapeData(x_test_samples, y_test_samples)\n",
    "\n",
    "print(x.shape, y_test.shape)\n",
    "\n",
    "print(x_test.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Test and Train datasets\n",
    "\n",
    "Combine all data sets in /train_data and /test_data into one, for more samples when training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Combine all datasets in a directory into one dataframe\n",
    "def CombineDatasets(path):\n",
    "    data_list = []\n",
    "    for file in os.listdir(path):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".csv\"):\n",
    "            df = pd.read_csv(path + filename)\n",
    "            \n",
    "            data_list.append(df)\n",
    "         \n",
    "    \n",
    "    data_df = pd.concat(data_list, axis=0, ignore_index=True)\n",
    "    display(data_df)\n",
    "\n",
    "    return data_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#combine data in a directory into two lists of x and y features\n",
    "def DatasetsLists(path):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    file_list = []\n",
    "    for file in os.listdir(path):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_list.append(filename)\n",
    "            df = pd.read_csv(path + filename)\n",
    "            x_features, y_features = SplitFeaturesLabels(df)\n",
    "            x_train, y_train = LoadArray(x_features, y_features)\n",
    "            x_normalized, y_normalized = NormalizeValues(x_train, y_train)\n",
    "            x_reshape, y_reshape = ReshapeData(x_normalized, y_normalized)\n",
    "            x_list.append(x_reshape)\n",
    "            y_list.append(y_reshape)\n",
    "    return x_list, y_list, file_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../train_data/\"\n",
    "x, y, files = DatasetsLists(train_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all data in the training data directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16108, 1, 9) (16108, 1, 9)\n"
     ]
    }
   ],
   "source": [
    "train_path = \"../train_data/\"\n",
    "\n",
    "combined_train_dataframe = CombineDatasets(train_path)\n",
    "\n",
    "x_train, y_train = SplitFeaturesLabels(combined_train_dataframe)\n",
    "        \n",
    "x_train_arr, y_train_arr = LoadArray(x_train, y_train)\n",
    "\n",
    "#Divide values in array by 100\n",
    "x_train_normalized, y_train_normalized = NormalizeValues(x_train_arr, y_train_arr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_train, y_train = ReshapeData(x_train_normalized, y_train_normalized)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all data in the test data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head_x</th>\n",
       "      <th>head_y</th>\n",
       "      <th>head_z</th>\n",
       "      <th>r_controller_x</th>\n",
       "      <th>r_controller_y</th>\n",
       "      <th>r_controller_z</th>\n",
       "      <th>l_controller_x</th>\n",
       "      <th>l_controller_y</th>\n",
       "      <th>l_controller_z</th>\n",
       "      <th>waist_x</th>\n",
       "      <th>waist_y</th>\n",
       "      <th>waist_z</th>\n",
       "      <th>r_foot_x</th>\n",
       "      <th>r_foot_y</th>\n",
       "      <th>r_foot_z</th>\n",
       "      <th>l_foot_x</th>\n",
       "      <th>l_foot_y</th>\n",
       "      <th>l_foot_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.488835</td>\n",
       "      <td>160.079437</td>\n",
       "      <td>-6.116605</td>\n",
       "      <td>29.804235</td>\n",
       "      <td>82.701195</td>\n",
       "      <td>-13.233584</td>\n",
       "      <td>-16.509771</td>\n",
       "      <td>80.914047</td>\n",
       "      <td>-10.186529</td>\n",
       "      <td>6.043923</td>\n",
       "      <td>102.261971</td>\n",
       "      <td>-9.864593</td>\n",
       "      <td>29.640865</td>\n",
       "      <td>11.117661</td>\n",
       "      <td>-0.257885</td>\n",
       "      <td>-10.534990</td>\n",
       "      <td>10.751200</td>\n",
       "      <td>0.808924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.444007</td>\n",
       "      <td>160.045471</td>\n",
       "      <td>-6.160123</td>\n",
       "      <td>29.804235</td>\n",
       "      <td>82.665466</td>\n",
       "      <td>-13.167156</td>\n",
       "      <td>-16.517654</td>\n",
       "      <td>80.914375</td>\n",
       "      <td>-10.194432</td>\n",
       "      <td>6.026009</td>\n",
       "      <td>102.261971</td>\n",
       "      <td>-9.864593</td>\n",
       "      <td>29.640865</td>\n",
       "      <td>11.117661</td>\n",
       "      <td>-0.257885</td>\n",
       "      <td>-10.534990</td>\n",
       "      <td>10.751200</td>\n",
       "      <td>0.808924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.398498</td>\n",
       "      <td>160.008942</td>\n",
       "      <td>-6.205270</td>\n",
       "      <td>29.804235</td>\n",
       "      <td>82.628105</td>\n",
       "      <td>-13.109230</td>\n",
       "      <td>-16.534975</td>\n",
       "      <td>80.898796</td>\n",
       "      <td>-10.199365</td>\n",
       "      <td>5.995472</td>\n",
       "      <td>102.261971</td>\n",
       "      <td>-9.876921</td>\n",
       "      <td>29.641844</td>\n",
       "      <td>11.117661</td>\n",
       "      <td>-0.257885</td>\n",
       "      <td>-10.534990</td>\n",
       "      <td>10.743254</td>\n",
       "      <td>0.804848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.354577</td>\n",
       "      <td>159.974304</td>\n",
       "      <td>-6.247052</td>\n",
       "      <td>29.786718</td>\n",
       "      <td>82.610161</td>\n",
       "      <td>-13.076245</td>\n",
       "      <td>-16.550200</td>\n",
       "      <td>80.881470</td>\n",
       "      <td>-10.200344</td>\n",
       "      <td>5.962020</td>\n",
       "      <td>102.265831</td>\n",
       "      <td>-9.900065</td>\n",
       "      <td>29.645809</td>\n",
       "      <td>11.117661</td>\n",
       "      <td>-0.257885</td>\n",
       "      <td>-10.534990</td>\n",
       "      <td>10.741699</td>\n",
       "      <td>0.795984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.303836</td>\n",
       "      <td>159.950211</td>\n",
       "      <td>-6.283061</td>\n",
       "      <td>29.740267</td>\n",
       "      <td>82.596954</td>\n",
       "      <td>-13.041903</td>\n",
       "      <td>-16.569069</td>\n",
       "      <td>80.867661</td>\n",
       "      <td>-10.196807</td>\n",
       "      <td>5.928277</td>\n",
       "      <td>102.269547</td>\n",
       "      <td>-9.921043</td>\n",
       "      <td>29.635088</td>\n",
       "      <td>11.117661</td>\n",
       "      <td>-0.257885</td>\n",
       "      <td>-10.544357</td>\n",
       "      <td>10.741123</td>\n",
       "      <td>0.791071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>-20.113129</td>\n",
       "      <td>162.799896</td>\n",
       "      <td>-9.994254</td>\n",
       "      <td>2.172675</td>\n",
       "      <td>77.998344</td>\n",
       "      <td>-0.433345</td>\n",
       "      <td>-28.572567</td>\n",
       "      <td>92.112686</td>\n",
       "      <td>-28.252392</td>\n",
       "      <td>-26.664967</td>\n",
       "      <td>102.839218</td>\n",
       "      <td>-10.404873</td>\n",
       "      <td>-5.554687</td>\n",
       "      <td>21.148430</td>\n",
       "      <td>4.580207</td>\n",
       "      <td>-32.508389</td>\n",
       "      <td>12.220007</td>\n",
       "      <td>6.545885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>-20.273098</td>\n",
       "      <td>162.799347</td>\n",
       "      <td>-9.995352</td>\n",
       "      <td>2.238370</td>\n",
       "      <td>78.053497</td>\n",
       "      <td>0.109862</td>\n",
       "      <td>-27.840115</td>\n",
       "      <td>92.877007</td>\n",
       "      <td>-28.771587</td>\n",
       "      <td>-26.376123</td>\n",
       "      <td>102.482895</td>\n",
       "      <td>-10.115138</td>\n",
       "      <td>-5.540289</td>\n",
       "      <td>21.570707</td>\n",
       "      <td>4.494763</td>\n",
       "      <td>-32.541687</td>\n",
       "      <td>12.190326</td>\n",
       "      <td>6.541198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>-20.423220</td>\n",
       "      <td>162.798996</td>\n",
       "      <td>-9.994866</td>\n",
       "      <td>2.335421</td>\n",
       "      <td>78.064072</td>\n",
       "      <td>0.679089</td>\n",
       "      <td>-27.143677</td>\n",
       "      <td>93.587799</td>\n",
       "      <td>-29.277714</td>\n",
       "      <td>-27.188471</td>\n",
       "      <td>103.277634</td>\n",
       "      <td>-10.786788</td>\n",
       "      <td>-5.494501</td>\n",
       "      <td>21.958044</td>\n",
       "      <td>4.434646</td>\n",
       "      <td>-32.541714</td>\n",
       "      <td>12.190485</td>\n",
       "      <td>6.540380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>-20.557684</td>\n",
       "      <td>162.809113</td>\n",
       "      <td>-9.987219</td>\n",
       "      <td>2.450321</td>\n",
       "      <td>78.071655</td>\n",
       "      <td>1.248731</td>\n",
       "      <td>-26.481314</td>\n",
       "      <td>94.256660</td>\n",
       "      <td>-29.745258</td>\n",
       "      <td>-26.866556</td>\n",
       "      <td>102.883896</td>\n",
       "      <td>-10.484671</td>\n",
       "      <td>-5.428247</td>\n",
       "      <td>22.294828</td>\n",
       "      <td>4.415785</td>\n",
       "      <td>-32.547028</td>\n",
       "      <td>12.190485</td>\n",
       "      <td>6.539558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>-20.669769</td>\n",
       "      <td>162.835815</td>\n",
       "      <td>-9.975833</td>\n",
       "      <td>2.577852</td>\n",
       "      <td>78.081947</td>\n",
       "      <td>1.808413</td>\n",
       "      <td>-25.857508</td>\n",
       "      <td>94.929451</td>\n",
       "      <td>-30.188917</td>\n",
       "      <td>-27.560795</td>\n",
       "      <td>103.617958</td>\n",
       "      <td>-11.086717</td>\n",
       "      <td>-5.351791</td>\n",
       "      <td>22.598917</td>\n",
       "      <td>4.415717</td>\n",
       "      <td>-32.537968</td>\n",
       "      <td>12.190485</td>\n",
       "      <td>6.538832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5400 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         head_x      head_y    head_z  r_controller_x  r_controller_y  \\\n",
       "0      7.488835  160.079437 -6.116605       29.804235       82.701195   \n",
       "1      7.444007  160.045471 -6.160123       29.804235       82.665466   \n",
       "2      7.398498  160.008942 -6.205270       29.804235       82.628105   \n",
       "3      7.354577  159.974304 -6.247052       29.786718       82.610161   \n",
       "4      7.303836  159.950211 -6.283061       29.740267       82.596954   \n",
       "...         ...         ...       ...             ...             ...   \n",
       "5395 -20.113129  162.799896 -9.994254        2.172675       77.998344   \n",
       "5396 -20.273098  162.799347 -9.995352        2.238370       78.053497   \n",
       "5397 -20.423220  162.798996 -9.994866        2.335421       78.064072   \n",
       "5398 -20.557684  162.809113 -9.987219        2.450321       78.071655   \n",
       "5399 -20.669769  162.835815 -9.975833        2.577852       78.081947   \n",
       "\n",
       "      r_controller_z  l_controller_x  l_controller_y  l_controller_z  \\\n",
       "0         -13.233584      -16.509771       80.914047      -10.186529   \n",
       "1         -13.167156      -16.517654       80.914375      -10.194432   \n",
       "2         -13.109230      -16.534975       80.898796      -10.199365   \n",
       "3         -13.076245      -16.550200       80.881470      -10.200344   \n",
       "4         -13.041903      -16.569069       80.867661      -10.196807   \n",
       "...              ...             ...             ...             ...   \n",
       "5395       -0.433345      -28.572567       92.112686      -28.252392   \n",
       "5396        0.109862      -27.840115       92.877007      -28.771587   \n",
       "5397        0.679089      -27.143677       93.587799      -29.277714   \n",
       "5398        1.248731      -26.481314       94.256660      -29.745258   \n",
       "5399        1.808413      -25.857508       94.929451      -30.188917   \n",
       "\n",
       "        waist_x     waist_y    waist_z   r_foot_x   r_foot_y  r_foot_z  \\\n",
       "0      6.043923  102.261971  -9.864593  29.640865  11.117661 -0.257885   \n",
       "1      6.026009  102.261971  -9.864593  29.640865  11.117661 -0.257885   \n",
       "2      5.995472  102.261971  -9.876921  29.641844  11.117661 -0.257885   \n",
       "3      5.962020  102.265831  -9.900065  29.645809  11.117661 -0.257885   \n",
       "4      5.928277  102.269547  -9.921043  29.635088  11.117661 -0.257885   \n",
       "...         ...         ...        ...        ...        ...       ...   \n",
       "5395 -26.664967  102.839218 -10.404873  -5.554687  21.148430  4.580207   \n",
       "5396 -26.376123  102.482895 -10.115138  -5.540289  21.570707  4.494763   \n",
       "5397 -27.188471  103.277634 -10.786788  -5.494501  21.958044  4.434646   \n",
       "5398 -26.866556  102.883896 -10.484671  -5.428247  22.294828  4.415785   \n",
       "5399 -27.560795  103.617958 -11.086717  -5.351791  22.598917  4.415717   \n",
       "\n",
       "       l_foot_x   l_foot_y  l_foot_z  \n",
       "0    -10.534990  10.751200  0.808924  \n",
       "1    -10.534990  10.751200  0.808924  \n",
       "2    -10.534990  10.743254  0.804848  \n",
       "3    -10.534990  10.741699  0.795984  \n",
       "4    -10.544357  10.741123  0.791071  \n",
       "...         ...        ...       ...  \n",
       "5395 -32.508389  12.220007  6.545885  \n",
       "5396 -32.541687  12.190326  6.541198  \n",
       "5397 -32.541714  12.190485  6.540380  \n",
       "5398 -32.547028  12.190485  6.539558  \n",
       "5399 -32.537968  12.190485  6.538832  \n",
       "\n",
       "[5400 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5400, 1, 9)\n",
      "[[[ 0.07488835  1.60079437 -0.06116605  0.29804235  0.82701195\n",
      "   -0.13233584 -0.16509771  0.80914047 -0.10186529]]]\n"
     ]
    }
   ],
   "source": [
    "test_path = \"../test_data/\"\n",
    "\n",
    "combined_test_dataframe = CombineDatasets(test_path)\n",
    "\n",
    "x_test, y_test = SplitFeaturesLabels(combined_test_dataframe)\n",
    "        \n",
    "x_test_arr, y_test_arr = LoadArray(x_test, y_test)\n",
    "\n",
    "x_test_normalized, y_test_normalized = NormalizeValues(x_test_arr, y_test_arr)\n",
    "\n",
    "\n",
    "x_test, y_test = ReshapeData(x_test_normalized, y_test_normalized)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(x_test[0:1,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required modules\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, BatchNormalization\n",
    "import tensorflow as tf\n",
    "from keras.layers import LSTM, GRU\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model to two equally sized lists of x features and y labels \n",
    "\n",
    "def FitToList(x, y, model, epoch, b_size, verbose):\n",
    "    for i in range(len(x)):\n",
    "        print(i)\n",
    "        print(x[i].shape)\n",
    "        print(y[i].shape)\n",
    "        model.fit(x[i], y[i], epochs=epoch,batch_size=b_size, verbose=verbose)\n",
    "    return epoch, b_size\n",
    "        \n",
    " # fit the model to a given set of features (x) and labels (y)    \n",
    "def FitModel(x, y, model, epoch, b_size):\n",
    "    model.fit(x, y, validation_split=0.33, epochs=epoch,batch_size = b_size)\n",
    "    return epoch, b_size\n",
    "\n",
    "    \n",
    "def EvaluateModel(x, y, model):\n",
    "    metrics = model.evaluate(x, y, batch_size=256)\n",
    "    print(\"test loss, test acc:\", metrics)\n",
    "    return metrics\n",
    "    \n",
    "    \n",
    "def PredictModel(x, y, model):\n",
    "    predictions = model.predict(x)\n",
    "    y_reshaped = y.reshape(-1,9)\n",
    "    x_reshaped = x.reshape(-1,9)\n",
    "    return predictions, y_reshaped, x_reshaped\n",
    "\n",
    "\n",
    "def DisplayPredictions(prediction, actual, predicted_on, range_1, range_2):\n",
    "    if range_2 <= 0:\n",
    "        r_1 = 0\n",
    "        r_2 = len(prediction)\n",
    "    else:\n",
    "        r_1 = range_1\n",
    "        r_2 = range_2\n",
    "    print(\"predictions shape:\", prediction.shape)\n",
    "    predicted_on_df = pd.DataFrame(predicted_on, columns=[\"Head_X\", \"Head_Y\", \"Head_Z\", \"R_Controller_X\", \"R_Controller_Y\", \"R_Controller_Z\", \"L_Controller_X\", \"L_Controller_Y\", \"L_Controller_Z\"])\n",
    "    prediction_df = pd.DataFrame(prediction, columns=[\"Waist_X\", \"Waist_Y\", \"Waist_Z\", \"R_Foot_X\", \"R_Foot_Y\", \"R_Foot_Z\", \"L_Foot_X\", \"L_Foot_Y\", \"L_Foot_Z\"])\n",
    "    actual_df = pd.DataFrame(actual, columns=[\"Waist_X\", \"Waist_Y\", \"Waist_Z\", \"R_Foot_X\", \"R_Foot_Y\", \"R_Foot_Z\", \"L_Foot_X\", \"L_Foot_Y\", \"L_Foot_Z\"])\n",
    "    print(\"Actual Values\")\n",
    "    display(actual_df[r_1:r_2])\n",
    "    print(\"Predicited Values\")\n",
    "    display(prediction_df[r_1:r_2])\n",
    "    return actual_df, prediction_df, predicted_on_df\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model compiled\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 1, 16)             1296      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 16)             0         \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 16)                1632      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,081\n",
      "Trainable params: 3,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(learning_rate=0.001, momentum=0.8, decay=0.999, nesterov=False)\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(16, return_sequences=True, input_shape=(5, 9)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(16, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(9, activation = \"linear\"))\n",
    "\n",
    "model.compile(loss='mse', optimizer=\"adam\")\n",
    "\n",
    "print ('model compiled')\n",
    "\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"gru_4\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m model_2\u001b[38;5;241m.\u001b[39madd(Dropout(\u001b[38;5;241m0.2\u001b[39m))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#Add Batch Normalization layer\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#model_2.add(BatchNormalization())\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mmodel_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGRU\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#Add dropout layer\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#model_2.add(Dropout(0.2))\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#Add Dense layer with 9 outputs\u001b[39;00m\n\u001b[0;32m     19\u001b[0m model_2\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m9\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:629\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 629\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py:214\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    212\u001b[0m   ndim \u001b[38;5;241m=\u001b[39m shape\u001b[38;5;241m.\u001b[39mrank\n\u001b[0;32m    213\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m!=\u001b[39m spec\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    215\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    216\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, found ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    217\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mmax_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    219\u001b[0m   ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"gru_4\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 64)"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "opt = SGD(learning_rate = 0.01)\n",
    "\n",
    "compile_params = [\"mse\", \"sgd\", \"accuracy\"]\n",
    "#add one GRU layer of 64 cellss with input shape 1,9\n",
    "model_2.add(GRU(64, input_shape=(1, 9)))\n",
    "\n",
    "model_2.add(Dropout(0.2))\n",
    "\n",
    "#Add Batch Normalization layer\n",
    "#model_2.add(BatchNormalization())\n",
    "\n",
    "#Add dropout layer\n",
    "#model_2.add(Dropout(0.2))\n",
    "\n",
    "#Add Dense layer with 9 outputs\n",
    "model_2.add(Dense(9))\n",
    "\n",
    "print(model_2.summary())\n",
    "\n",
    "\n",
    "#Compile model\n",
    "model_2.compile(\n",
    "    loss = compile_params[0],\n",
    "    optimizer = opt,\n",
    "    metrics = [compile_params[2]],\n",
    ")\n",
    "\n",
    "\n",
    "print(model_2.compiled_loss._losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 606, 600, 600, 600, 600, 600, 600, 600, 606, 600, 600, 600, 606, 600, 600, 600, 600, 600, 600, 600, 606, 600, 600, 600, 600, 600, 606, 606, 600, 600, 600, 600, 600\n  y sizes: 606, 600, 600, 600, 600, 600, 600, 600, 606, 600, 600, 600, 606, 600, 600, 600, 600, 600, 600, 600, 606, 600, 600, 600, 600, 600, 606, 606, 600, 600, 600, 600, 600\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m epochs, batch_size \u001b[38;5;241m=\u001b[39m \u001b[43mFitModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36mFitModel\u001b[1;34m(x, y, model, epoch, b_size)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mFitModel\u001b[39m(x, y, model, epoch, b_size):\n\u001b[1;32m---> 13\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.33\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m epoch, b_size\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py:1653\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1649\u001b[0m   msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1650\u001b[0m       label, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1651\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)))\n\u001b[0;32m   1652\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1653\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 606, 600, 600, 600, 600, 600, 600, 600, 606, 600, 600, 600, 606, 600, 600, 600, 600, 600, 600, 600, 606, 600, 600, 600, 600, 600, 606, 606, 600, 600, 600, 600, 600\n  y sizes: 606, 600, 600, 600, 600, 600, 600, 600, 606, 600, 600, 600, 606, 600, 600, 600, 600, 600, 600, 600, 606, 600, 600, 600, 600, 600, 606, 606, 600, 600, 600, 600, 600\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "epochs, batch_size = FitModel(x, y, model_2, 1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(905, 1, 9)\n",
      "(905, 1, 9)\n",
      "Epoch 1/20\n",
      "905/905 [==============================] - 2s 978us/step - loss: 0.0150 - accuracy: 0.9768\n",
      "Epoch 2/20\n",
      "905/905 [==============================] - 1s 877us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "905/905 [==============================] - 1s 817us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "905/905 [==============================] - 1s 943us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "905/905 [==============================] - 1s 967us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "905/905 [==============================] - 1s 1ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "905/905 [==============================] - 1s 1ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "905/905 [==============================] - 1s 821us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "905/905 [==============================] - 1s 819us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "905/905 [==============================] - 1s 833us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "905/905 [==============================] - 1s 823us/step - loss: 9.7534e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "905/905 [==============================] - 1s 821us/step - loss: 8.7609e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "905/905 [==============================] - 1s 822us/step - loss: 8.1399e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "905/905 [==============================] - 1s 818us/step - loss: 7.7441e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "905/905 [==============================] - 1s 812us/step - loss: 7.1497e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "905/905 [==============================] - 1s 835us/step - loss: 6.7199e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "905/905 [==============================] - 1s 862us/step - loss: 6.1310e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "905/905 [==============================] - 1s 819us/step - loss: 6.2421e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "905/905 [==============================] - 1s 829us/step - loss: 5.8386e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "905/905 [==============================] - 1s 822us/step - loss: 5.6528e-04 - accuracy: 1.0000\n",
      "1\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 0s 808us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 837us/step - loss: 6.3771e-04 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 821us/step - loss: 5.9515e-04 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 806us/step - loss: 5.6061e-04 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 821us/step - loss: 5.1942e-04 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 835us/step - loss: 5.3489e-04 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 819us/step - loss: 4.6596e-04 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 816us/step - loss: 4.7426e-04 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 860us/step - loss: 4.2683e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 844us/step - loss: 4.2285e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 811us/step - loss: 4.1490e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 828us/step - loss: 3.9372e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 839us/step - loss: 3.6728e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 864us/step - loss: 3.6195e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 825us/step - loss: 3.6845e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 884us/step - loss: 3.3735e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 816us/step - loss: 3.6034e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 815us/step - loss: 3.2530e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 801us/step - loss: 3.0136e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 818us/step - loss: 2.9229e-04 - accuracy: 1.0000\n",
      "2\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 0s 823us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 824us/step - loss: 6.1340e-04 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 814us/step - loss: 5.7021e-04 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 822us/step - loss: 4.9271e-04 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 851us/step - loss: 4.4462e-04 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 824us/step - loss: 3.8818e-04 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 841us/step - loss: 3.7449e-04 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 827us/step - loss: 3.4267e-04 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 836us/step - loss: 3.0809e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 823us/step - loss: 2.9667e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 844us/step - loss: 2.8327e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 851us/step - loss: 2.7212e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 812us/step - loss: 2.5564e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 822us/step - loss: 2.3720e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 826us/step - loss: 2.2781e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 867us/step - loss: 2.2540e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 838us/step - loss: 2.1619e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 809us/step - loss: 2.0152e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 833us/step - loss: 1.9774e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 838us/step - loss: 1.9761e-04 - accuracy: 1.0000\n",
      "3\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 833us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 863us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 845us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 838us/step - loss: 9.6557e-04 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 831us/step - loss: 8.7823e-04 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 814us/step - loss: 8.1655e-04 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 826us/step - loss: 7.7233e-04 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 832us/step - loss: 7.3122e-04 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 818us/step - loss: 7.1361e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 834us/step - loss: 6.7855e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 833us/step - loss: 6.5743e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 835us/step - loss: 6.4459e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 805us/step - loss: 6.1493e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 808us/step - loss: 6.1825e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 859us/step - loss: 6.0130e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 804us/step - loss: 5.8293e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 813us/step - loss: 5.5521e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 808us/step - loss: 5.7050e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 824us/step - loss: 5.4875e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 831us/step - loss: 5.4562e-04 - accuracy: 1.0000\n",
      "4\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 0s 811us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 794us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 823us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 811us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 839us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 824us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 824us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 808us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 829us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 809us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 812us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 827us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 811us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 881us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 812us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 832us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 817us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 819us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 803us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 828us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "5\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 0s 825us/step - loss: 0.0796 - accuracy: 0.3383\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 817us/step - loss: 0.0390 - accuracy: 0.6000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 814us/step - loss: 0.0339 - accuracy: 0.6050\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 850us/step - loss: 0.0319 - accuracy: 0.6233\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 883us/step - loss: 0.0301 - accuracy: 0.6500\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0292 - accuracy: 0.6483\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0277 - accuracy: 0.6500\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0264 - accuracy: 0.6617\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0256 - accuracy: 0.6750\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0236 - accuracy: 0.6850\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0233 - accuracy: 0.6883\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0217 - accuracy: 0.7300\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 974us/step - loss: 0.0211 - accuracy: 0.7167\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0202 - accuracy: 0.7200\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0190 - accuracy: 0.7483\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0185 - accuracy: 0.7300\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 993us/step - loss: 0.0176 - accuracy: 0.7283\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0170 - accuracy: 0.7517\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0163 - accuracy: 0.7550\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0160 - accuracy: 0.7517\n",
      "6\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0279 - accuracy: 0.9300\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0234 - accuracy: 0.9417\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0221 - accuracy: 0.9450\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 997us/step - loss: 0.0217 - accuracy: 0.9383\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 842us/step - loss: 0.0210 - accuracy: 0.9350\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 838us/step - loss: 0.0202 - accuracy: 0.9317\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 823us/step - loss: 0.0195 - accuracy: 0.9400\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 824us/step - loss: 0.0187 - accuracy: 0.9350\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 846us/step - loss: 0.0181 - accuracy: 0.9350\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 869us/step - loss: 0.0174 - accuracy: 0.9417\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 864us/step - loss: 0.0170 - accuracy: 0.9433\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 820us/step - loss: 0.0164 - accuracy: 0.9333\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 879us/step - loss: 0.0157 - accuracy: 0.9483\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 855us/step - loss: 0.0154 - accuracy: 0.9383\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 832us/step - loss: 0.0144 - accuracy: 0.9383\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 842us/step - loss: 0.0139 - accuracy: 0.9383\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 851us/step - loss: 0.0137 - accuracy: 0.9400\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 842us/step - loss: 0.0132 - accuracy: 0.9350\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 829us/step - loss: 0.0126 - accuracy: 0.9350\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 836us/step - loss: 0.0121 - accuracy: 0.9417\n",
      "7\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 845us/step - loss: 0.0340 - accuracy: 0.9800\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 843us/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 854us/step - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 838us/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 845us/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 823us/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 865us/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 814us/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 900us/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 840us/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 840us/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 831us/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 831us/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 835us/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 835us/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 814us/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 840us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 834us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 826us/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 844us/step - loss: 0.0077 - accuracy: 1.0000\n",
      "8\n",
      "(916, 1, 9)\n",
      "(916, 1, 9)\n",
      "Epoch 1/20\n",
      "916/916 [==============================] - 1s 827us/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "916/916 [==============================] - 1s 825us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "916/916 [==============================] - 1s 825us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "916/916 [==============================] - 1s 822us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "916/916 [==============================] - 1s 828us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "916/916 [==============================] - 1s 820us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "916/916 [==============================] - 1s 842us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "916/916 [==============================] - 1s 824us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "916/916 [==============================] - 1s 818us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "916/916 [==============================] - 1s 816us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "916/916 [==============================] - 1s 813us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "916/916 [==============================] - 1s 846us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "916/916 [==============================] - 1s 822us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "916/916 [==============================] - 1s 848us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "916/916 [==============================] - 1s 842us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "916/916 [==============================] - 1s 829us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "916/916 [==============================] - 1s 849us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "916/916 [==============================] - 1s 826us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "916/916 [==============================] - 1s 832us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "916/916 [==============================] - 1s 825us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "9\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 882us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 839us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 836us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 830us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 836us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 810us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 843us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 822us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 845us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 816us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 826us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 819us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 840us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 808us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 851us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 825us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 867us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 821us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 841us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 841us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "10\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 863us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 838us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 844us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 851us/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 852us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 812us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 837us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 835us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 859us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 847us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 863us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 829us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 852us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 830us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 840us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 830us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 841us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 856us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 858us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 855us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "11\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 902us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 822us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 842us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 838us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 820us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 832us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 838us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 832us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 835us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 845us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 851us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 830us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 855us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 822us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 829us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 814us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 814us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 817us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 819us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 819us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "12\n",
      "(934, 1, 9)\n",
      "(934, 1, 9)\n",
      "Epoch 1/20\n",
      "934/934 [==============================] - 1s 872us/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "934/934 [==============================] - 1s 818us/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "934/934 [==============================] - 1s 828us/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "934/934 [==============================] - 1s 839us/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "934/934 [==============================] - 1s 808us/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "934/934 [==============================] - 1s 815us/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "934/934 [==============================] - 1s 848us/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "934/934 [==============================] - 1s 849us/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "934/934 [==============================] - 1s 832us/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "934/934 [==============================] - 1s 853us/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "934/934 [==============================] - 1s 845us/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "934/934 [==============================] - 1s 839us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "934/934 [==============================] - 1s 848us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "934/934 [==============================] - 1s 892us/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "934/934 [==============================] - 1s 854us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "934/934 [==============================] - 1s 840us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "934/934 [==============================] - 1s 840us/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "934/934 [==============================] - 1s 849us/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "934/934 [==============================] - 1s 837us/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "934/934 [==============================] - 1s 858us/step - loss: 0.0061 - accuracy: 1.0000\n",
      "13\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 841us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 843us/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 850us/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 847us/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 865us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 817us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 840us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 906us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 850us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 842us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 847us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 832us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 832us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 822us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 827us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 830us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 837us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 845us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 825us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 832us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "14\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 843us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 849us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 833us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 838us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 836us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 839us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 837us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 845us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 858us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 842us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 858us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 828us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 841us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 848us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 846us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 836us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 825us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 867us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 832us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 834us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "15\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 854us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 816us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 835us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 871us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 839us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 833us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 842us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 854us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 851us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 837us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 821us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 836us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 835us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 835us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 831us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 891us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 824us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 816us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 844us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 0s 823us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "16\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 838us/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 851us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 815us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 848us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 847us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 863us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 831us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 843us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 799us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 823us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 832us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 863us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 822us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 936us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 828us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 830us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 905us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 835us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 835us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 847us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "17\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 833us/step - loss: 0.0118 - accuracy: 0.7433\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 825us/step - loss: 0.0066 - accuracy: 0.8300\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 827us/step - loss: 0.0050 - accuracy: 0.9300\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 823us/step - loss: 0.0043 - accuracy: 0.9383\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 824us/step - loss: 0.0038 - accuracy: 0.9783\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 814us/step - loss: 0.0037 - accuracy: 0.9733\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 823us/step - loss: 0.0034 - accuracy: 0.9833\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 833us/step - loss: 0.0034 - accuracy: 0.9883\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 838us/step - loss: 0.0032 - accuracy: 0.9833\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 819us/step - loss: 0.0031 - accuracy: 0.9867\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 826us/step - loss: 0.0030 - accuracy: 0.9983\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 814us/step - loss: 0.0030 - accuracy: 0.9900\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 823us/step - loss: 0.0030 - accuracy: 0.9917\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 890us/step - loss: 0.0029 - accuracy: 0.9933\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 832us/step - loss: 0.0028 - accuracy: 0.9900\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 820us/step - loss: 0.0027 - accuracy: 0.9933\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 826us/step - loss: 0.0027 - accuracy: 0.9917\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 853us/step - loss: 0.0027 - accuracy: 0.9967\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 842us/step - loss: 0.0027 - accuracy: 0.9950\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 838us/step - loss: 0.0026 - accuracy: 0.9983\n",
      "18\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 0s 822us/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 842us/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 855us/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 838us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 828us/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 843us/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 818us/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 824us/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 821us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 838us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 817us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 829us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 841us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 844us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 841us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 842us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 860us/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 860us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 835us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 839us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "19\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 0s 831us/step - loss: 0.0296 - accuracy: 0.5250\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 0s 825us/step - loss: 0.0199 - accuracy: 0.5250\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 0s 824us/step - loss: 0.0163 - accuracy: 0.5283\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 0s 824us/step - loss: 0.0138 - accuracy: 0.5333\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 845us/step - loss: 0.0124 - accuracy: 0.5450\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 824us/step - loss: 0.0112 - accuracy: 0.5750\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 0s 822us/step - loss: 0.0103 - accuracy: 0.5933\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 831us/step - loss: 0.0096 - accuracy: 0.6250\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 830us/step - loss: 0.0091 - accuracy: 0.6333\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 849us/step - loss: 0.0084 - accuracy: 0.6700\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 846us/step - loss: 0.0081 - accuracy: 0.6850\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 849us/step - loss: 0.0078 - accuracy: 0.6717\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 828us/step - loss: 0.0074 - accuracy: 0.7117\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 842us/step - loss: 0.0071 - accuracy: 0.7217\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 835us/step - loss: 0.0071 - accuracy: 0.7267\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 847us/step - loss: 0.0068 - accuracy: 0.7200\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 851us/step - loss: 0.0065 - accuracy: 0.7400\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 894us/step - loss: 0.0064 - accuracy: 0.7483\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 866us/step - loss: 0.0062 - accuracy: 0.7583\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 847us/step - loss: 0.0061 - accuracy: 0.7600\n",
      "20\n",
      "(1103, 1, 9)\n",
      "(1103, 1, 9)\n",
      "Epoch 1/20\n",
      "1103/1103 [==============================] - 1s 851us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "1103/1103 [==============================] - 1s 843us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "1103/1103 [==============================] - 1s 835us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "1103/1103 [==============================] - 1s 834us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "1103/1103 [==============================] - 1s 845us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "1103/1103 [==============================] - 1s 849us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "1103/1103 [==============================] - 1s 834us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "1103/1103 [==============================] - 1s 814us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "1103/1103 [==============================] - 1s 836us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "1103/1103 [==============================] - 1s 833us/step - loss: 9.5976e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "1103/1103 [==============================] - 1s 834us/step - loss: 9.0770e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "1103/1103 [==============================] - 1s 837us/step - loss: 8.4982e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "1103/1103 [==============================] - 1s 828us/step - loss: 8.4063e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "1103/1103 [==============================] - 1s 856us/step - loss: 8.0632e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "1103/1103 [==============================] - 1s 847us/step - loss: 7.6409e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "1103/1103 [==============================] - 1s 826us/step - loss: 7.3810e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1103/1103 [==============================] - 1s 828us/step - loss: 7.2604e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1103/1103 [==============================] - 1s 846us/step - loss: 6.9227e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1103/1103 [==============================] - 1s 830us/step - loss: 6.6421e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1103/1103 [==============================] - 1s 830us/step - loss: 6.7174e-04 - accuracy: 1.0000\n",
      "21\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 855us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 883us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 840us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 839us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 837us/step - loss: 9.3344e-04 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 829us/step - loss: 9.2839e-04 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 851us/step - loss: 8.8671e-04 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 817us/step - loss: 8.3979e-04 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 832us/step - loss: 8.3623e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 833us/step - loss: 8.3567e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 0s 815us/step - loss: 8.1050e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 833us/step - loss: 7.8822e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 0s 826us/step - loss: 7.7411e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 825us/step - loss: 7.5822e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 0s 808us/step - loss: 7.1310e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 831us/step - loss: 7.2478e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 824us/step - loss: 7.1020e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 834us/step - loss: 6.9872e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 835us/step - loss: 6.7373e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 848us/step - loss: 6.6921e-04 - accuracy: 1.0000\n",
      "22\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 0s 821us/step - loss: 7.4236e-04 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 849us/step - loss: 5.7808e-04 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 851us/step - loss: 5.5484e-04 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 838us/step - loss: 5.4016e-04 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 845us/step - loss: 5.0581e-04 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 837us/step - loss: 5.3609e-04 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 838us/step - loss: 4.7293e-04 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 861us/step - loss: 4.8540e-04 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 0s 823us/step - loss: 4.7508e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 840us/step - loss: 4.6419e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 849us/step - loss: 4.4407e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 0s 818us/step - loss: 4.3878e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 878us/step - loss: 4.2916e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 0s 818us/step - loss: 4.4001e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 839us/step - loss: 4.0929e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 0s 811us/step - loss: 4.1514e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 865us/step - loss: 4.0847e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 0s 819us/step - loss: 4.0222e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 868us/step - loss: 3.9820e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 853us/step - loss: 3.8440e-04 - accuracy: 1.0000\n",
      "23\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 885us/step - loss: 0.0046 - accuracy: 0.8217\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 909us/step - loss: 0.0019 - accuracy: 0.8267\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 837us/step - loss: 0.0017 - accuracy: 0.8417\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 843us/step - loss: 0.0017 - accuracy: 0.8450\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 0s 828us/step - loss: 0.0016 - accuracy: 0.8483\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 846us/step - loss: 0.0015 - accuracy: 0.8383\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 838us/step - loss: 0.0013 - accuracy: 0.8817\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 855us/step - loss: 0.0014 - accuracy: 0.8533\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 844us/step - loss: 0.0013 - accuracy: 0.8700\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 0s 832us/step - loss: 0.0012 - accuracy: 0.8717\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 839us/step - loss: 0.0012 - accuracy: 0.8750\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 835us/step - loss: 0.0011 - accuracy: 0.8650\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 851us/step - loss: 0.0011 - accuracy: 0.8850\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 833us/step - loss: 0.0010 - accuracy: 0.8733\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 834us/step - loss: 0.0011 - accuracy: 0.8800\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 839us/step - loss: 0.0010 - accuracy: 0.8733\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 0s 825us/step - loss: 9.9605e-04 - accuracy: 0.8733\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 836us/step - loss: 9.3274e-04 - accuracy: 0.8900\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 0s 832us/step - loss: 8.8342e-04 - accuracy: 0.9000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 867us/step - loss: 8.8781e-04 - accuracy: 0.8883\n",
      "24\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 841us/step - loss: 0.0460 - accuracy: 0.9983\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 871us/step - loss: 0.0190 - accuracy: 0.9933\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 838us/step - loss: 0.0150 - accuracy: 0.9933\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 837us/step - loss: 0.0145 - accuracy: 0.9950\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 846us/step - loss: 0.0137 - accuracy: 0.9917\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 850us/step - loss: 0.0134 - accuracy: 0.9967\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 866us/step - loss: 0.0125 - accuracy: 0.9950\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 0s 807us/step - loss: 0.0122 - accuracy: 0.9967\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 842us/step - loss: 0.0118 - accuracy: 0.9950\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 933us/step - loss: 0.0114 - accuracy: 0.9967\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0113 - accuracy: 0.9900\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0110 - accuracy: 0.9950\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 961us/step - loss: 0.0108 - accuracy: 0.9917\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 864us/step - loss: 0.0105 - accuracy: 0.9967\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 835us/step - loss: 0.0105 - accuracy: 0.9967\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0101 - accuracy: 0.9933\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0098 - accuracy: 0.9983\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0101 - accuracy: 0.9950\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 902us/step - loss: 0.0100 - accuracy: 0.9950\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0097 - accuracy: 0.9950\n",
      "25\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0373 - accuracy: 0.8000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 953us/step - loss: 0.0192 - accuracy: 0.8050\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 912us/step - loss: 0.0170 - accuracy: 0.8233\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0164 - accuracy: 0.8300\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0164 - accuracy: 0.8383\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 0s 830us/step - loss: 0.0154 - accuracy: 0.8433\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 920us/step - loss: 0.0155 - accuracy: 0.8517\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 981us/step - loss: 0.0144 - accuracy: 0.8433\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 892us/step - loss: 0.0142 - accuracy: 0.8567\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0142 - accuracy: 0.8483\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0145 - accuracy: 0.8617\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 999us/step - loss: 0.0134 - accuracy: 0.8483\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0135 - accuracy: 0.8500\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0134 - accuracy: 0.8650\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0128 - accuracy: 0.8567\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0130 - accuracy: 0.8533\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0126 - accuracy: 0.8617\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 905us/step - loss: 0.0126 - accuracy: 0.8567\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 879us/step - loss: 0.0124 - accuracy: 0.8817\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 882us/step - loss: 0.0127 - accuracy: 0.8717\n",
      "26\n",
      "(972, 1, 9)\n",
      "(972, 1, 9)\n",
      "Epoch 1/20\n",
      "972/972 [==============================] - 1s 1ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "972/972 [==============================] - 1s 1ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "972/972 [==============================] - 1s 914us/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "972/972 [==============================] - 1s 835us/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "972/972 [==============================] - 1s 924us/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "972/972 [==============================] - 1s 953us/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "972/972 [==============================] - 1s 881us/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "972/972 [==============================] - 1s 1ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "972/972 [==============================] - 1s 1ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "972/972 [==============================] - 1s 1ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "972/972 [==============================] - 1s 829us/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "972/972 [==============================] - 1s 816us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "972/972 [==============================] - 1s 836us/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "972/972 [==============================] - 1s 817us/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "972/972 [==============================] - 1s 844us/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "972/972 [==============================] - 1s 837us/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "972/972 [==============================] - 1s 824us/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "972/972 [==============================] - 1s 824us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "972/972 [==============================] - 1s 828us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "972/972 [==============================] - 1s 827us/step - loss: 0.0078 - accuracy: 1.0000\n",
      "27\n",
      "(1078, 1, 9)\n",
      "(1078, 1, 9)\n",
      "Epoch 1/20\n",
      "1078/1078 [==============================] - 1s 854us/step - loss: 0.0154 - accuracy: 0.9221\n",
      "Epoch 2/20\n",
      "1078/1078 [==============================] - 1s 861us/step - loss: 0.0113 - accuracy: 0.9323\n",
      "Epoch 3/20\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0100 - accuracy: 0.9360\n",
      "Epoch 4/20\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0096 - accuracy: 0.9443\n",
      "Epoch 5/20\n",
      "1078/1078 [==============================] - 1s 983us/step - loss: 0.0096 - accuracy: 0.9481\n",
      "Epoch 6/20\n",
      "1078/1078 [==============================] - 1s 994us/step - loss: 0.0094 - accuracy: 0.9573\n",
      "Epoch 7/20\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0093 - accuracy: 0.9508\n",
      "Epoch 8/20\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0093 - accuracy: 0.9564\n",
      "Epoch 9/20\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0092 - accuracy: 0.9536\n",
      "Epoch 10/20\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0089 - accuracy: 0.9555\n",
      "Epoch 11/20\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0091 - accuracy: 0.9564\n",
      "Epoch 12/20\n",
      "1078/1078 [==============================] - 1s 928us/step - loss: 0.0091 - accuracy: 0.9527\n",
      "Epoch 13/20\n",
      "1078/1078 [==============================] - 1s 997us/step - loss: 0.0089 - accuracy: 0.9545\n",
      "Epoch 14/20\n",
      "1078/1078 [==============================] - 1s 957us/step - loss: 0.0087 - accuracy: 0.9462\n",
      "Epoch 15/20\n",
      "1078/1078 [==============================] - 1s 979us/step - loss: 0.0088 - accuracy: 0.9545\n",
      "Epoch 16/20\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0089 - accuracy: 0.9545\n",
      "Epoch 17/20\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0086 - accuracy: 0.9555\n",
      "Epoch 18/20\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0087 - accuracy: 0.9620\n",
      "Epoch 19/20\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0086 - accuracy: 0.9638\n",
      "Epoch 20/20\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0085 - accuracy: 0.9527\n",
      "28\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 946us/step - loss: 0.0091 - accuracy: 0.9983\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 897us/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 931us/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 885us/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 914us/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 870us/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 974us/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 968us/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 992us/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 997us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 950us/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "29\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 986us/step - loss: 0.0202 - accuracy: 0.8317\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0142 - accuracy: 0.8517\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0118 - accuracy: 0.8783\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0106 - accuracy: 0.8917\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0099 - accuracy: 0.9133\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0098 - accuracy: 0.9267\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 992us/step - loss: 0.0092 - accuracy: 0.9267\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 991us/step - loss: 0.0090 - accuracy: 0.9350\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0090 - accuracy: 0.9400\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0091 - accuracy: 0.9383\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 905us/step - loss: 0.0089 - accuracy: 0.9300\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 883us/step - loss: 0.0089 - accuracy: 0.9333\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 867us/step - loss: 0.0090 - accuracy: 0.9400\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 850us/step - loss: 0.0087 - accuracy: 0.9467\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 918us/step - loss: 0.0088 - accuracy: 0.9250\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 968us/step - loss: 0.0085 - accuracy: 0.9450\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0087 - accuracy: 0.9400\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0086 - accuracy: 0.9450\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 944us/step - loss: 0.0086 - accuracy: 0.9267\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 962us/step - loss: 0.0085 - accuracy: 0.9383\n",
      "30\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 910us/step - loss: 0.0221 - accuracy: 0.7717\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 947us/step - loss: 0.0150 - accuracy: 0.8100\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0124 - accuracy: 0.8400\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 919us/step - loss: 0.0108 - accuracy: 0.8900\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 996us/step - loss: 0.0101 - accuracy: 0.9167\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0096 - accuracy: 0.9433\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 947us/step - loss: 0.0095 - accuracy: 0.9333\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 841us/step - loss: 0.0096 - accuracy: 0.9383\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 868us/step - loss: 0.0092 - accuracy: 0.9333\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 930us/step - loss: 0.0091 - accuracy: 0.9333\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 958us/step - loss: 0.0093 - accuracy: 0.9450\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0091 - accuracy: 0.9400\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 994us/step - loss: 0.0089 - accuracy: 0.9350\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0091 - accuracy: 0.9350\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 973us/step - loss: 0.0089 - accuracy: 0.9367\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 950us/step - loss: 0.0089 - accuracy: 0.9367\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 859us/step - loss: 0.0091 - accuracy: 0.9300\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 966us/step - loss: 0.0088 - accuracy: 0.9450\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0088 - accuracy: 0.9500\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0088 - accuracy: 0.9483\n",
      "31\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0179 - accuracy: 0.8350\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 898us/step - loss: 0.0143 - accuracy: 0.8150\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 841us/step - loss: 0.0129 - accuracy: 0.8217\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0124 - accuracy: 0.8200\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0122 - accuracy: 0.8217\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 921us/step - loss: 0.0123 - accuracy: 0.8200\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 992us/step - loss: 0.0121 - accuracy: 0.8050\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 896us/step - loss: 0.0117 - accuracy: 0.8217\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0114 - accuracy: 0.8217\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0112 - accuracy: 0.8250\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0112 - accuracy: 0.8233\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0109 - accuracy: 0.8117\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 926us/step - loss: 0.0109 - accuracy: 0.8233\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0108 - accuracy: 0.8400\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 850us/step - loss: 0.0104 - accuracy: 0.8200\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0104 - accuracy: 0.8283\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0101 - accuracy: 0.8417\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 986us/step - loss: 0.0103 - accuracy: 0.8350\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 912us/step - loss: 0.0103 - accuracy: 0.8283\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 923us/step - loss: 0.0103 - accuracy: 0.8233\n",
      "32\n",
      "(600, 1, 9)\n",
      "(600, 1, 9)\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1s 919us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1s 978us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1s 891us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 1s 952us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 1s 929us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 1s 947us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 1s 959us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 1s 920us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 1s 937us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 1s 1ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Fit list of datasets to model\n",
    "\n",
    "#training_x, training_y, model to train on, epoch count, batch size, ?verbose\n",
    "epochs, batch_size = FitToList(x, y, model_2, 20, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0771 - accuracy: 0.7832\n",
      "test loss, test acc: [0.0771242435278233, 0.7832313601078418]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = EvaluateModel(x_test, y_test, model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape: (5400, 9)\n",
      "Actual Values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Waist_X</th>\n",
       "      <th>Waist_Y</th>\n",
       "      <th>Waist_Z</th>\n",
       "      <th>R_Foot_X</th>\n",
       "      <th>R_Foot_Y</th>\n",
       "      <th>R_Foot_Z</th>\n",
       "      <th>L_Foot_X</th>\n",
       "      <th>L_Foot_Y</th>\n",
       "      <th>L_Foot_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.060439</td>\n",
       "      <td>1.022620</td>\n",
       "      <td>-0.098646</td>\n",
       "      <td>0.296409</td>\n",
       "      <td>0.111177</td>\n",
       "      <td>-0.002579</td>\n",
       "      <td>-0.105350</td>\n",
       "      <td>0.107512</td>\n",
       "      <td>0.008089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.060260</td>\n",
       "      <td>1.022620</td>\n",
       "      <td>-0.098646</td>\n",
       "      <td>0.296409</td>\n",
       "      <td>0.111177</td>\n",
       "      <td>-0.002579</td>\n",
       "      <td>-0.105350</td>\n",
       "      <td>0.107512</td>\n",
       "      <td>0.008089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059955</td>\n",
       "      <td>1.022620</td>\n",
       "      <td>-0.098769</td>\n",
       "      <td>0.296418</td>\n",
       "      <td>0.111177</td>\n",
       "      <td>-0.002579</td>\n",
       "      <td>-0.105350</td>\n",
       "      <td>0.107433</td>\n",
       "      <td>0.008048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059620</td>\n",
       "      <td>1.022658</td>\n",
       "      <td>-0.099001</td>\n",
       "      <td>0.296458</td>\n",
       "      <td>0.111177</td>\n",
       "      <td>-0.002579</td>\n",
       "      <td>-0.105350</td>\n",
       "      <td>0.107417</td>\n",
       "      <td>0.007960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059283</td>\n",
       "      <td>1.022695</td>\n",
       "      <td>-0.099210</td>\n",
       "      <td>0.296351</td>\n",
       "      <td>0.111177</td>\n",
       "      <td>-0.002579</td>\n",
       "      <td>-0.105444</td>\n",
       "      <td>0.107411</td>\n",
       "      <td>0.007911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>-0.266650</td>\n",
       "      <td>1.028392</td>\n",
       "      <td>-0.104049</td>\n",
       "      <td>-0.055547</td>\n",
       "      <td>0.211484</td>\n",
       "      <td>0.045802</td>\n",
       "      <td>-0.325084</td>\n",
       "      <td>0.122200</td>\n",
       "      <td>0.065459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>-0.263761</td>\n",
       "      <td>1.024829</td>\n",
       "      <td>-0.101151</td>\n",
       "      <td>-0.055403</td>\n",
       "      <td>0.215707</td>\n",
       "      <td>0.044948</td>\n",
       "      <td>-0.325417</td>\n",
       "      <td>0.121903</td>\n",
       "      <td>0.065412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>-0.271885</td>\n",
       "      <td>1.032776</td>\n",
       "      <td>-0.107868</td>\n",
       "      <td>-0.054945</td>\n",
       "      <td>0.219580</td>\n",
       "      <td>0.044346</td>\n",
       "      <td>-0.325417</td>\n",
       "      <td>0.121905</td>\n",
       "      <td>0.065404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>-0.268666</td>\n",
       "      <td>1.028839</td>\n",
       "      <td>-0.104847</td>\n",
       "      <td>-0.054282</td>\n",
       "      <td>0.222948</td>\n",
       "      <td>0.044158</td>\n",
       "      <td>-0.325470</td>\n",
       "      <td>0.121905</td>\n",
       "      <td>0.065396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>-0.275608</td>\n",
       "      <td>1.036180</td>\n",
       "      <td>-0.110867</td>\n",
       "      <td>-0.053518</td>\n",
       "      <td>0.225989</td>\n",
       "      <td>0.044157</td>\n",
       "      <td>-0.325380</td>\n",
       "      <td>0.121905</td>\n",
       "      <td>0.065388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5400 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Waist_X   Waist_Y   Waist_Z  R_Foot_X  R_Foot_Y  R_Foot_Z  L_Foot_X  \\\n",
       "0     0.060439  1.022620 -0.098646  0.296409  0.111177 -0.002579 -0.105350   \n",
       "1     0.060260  1.022620 -0.098646  0.296409  0.111177 -0.002579 -0.105350   \n",
       "2     0.059955  1.022620 -0.098769  0.296418  0.111177 -0.002579 -0.105350   \n",
       "3     0.059620  1.022658 -0.099001  0.296458  0.111177 -0.002579 -0.105350   \n",
       "4     0.059283  1.022695 -0.099210  0.296351  0.111177 -0.002579 -0.105444   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5395 -0.266650  1.028392 -0.104049 -0.055547  0.211484  0.045802 -0.325084   \n",
       "5396 -0.263761  1.024829 -0.101151 -0.055403  0.215707  0.044948 -0.325417   \n",
       "5397 -0.271885  1.032776 -0.107868 -0.054945  0.219580  0.044346 -0.325417   \n",
       "5398 -0.268666  1.028839 -0.104847 -0.054282  0.222948  0.044158 -0.325470   \n",
       "5399 -0.275608  1.036180 -0.110867 -0.053518  0.225989  0.044157 -0.325380   \n",
       "\n",
       "      L_Foot_Y  L_Foot_Z  \n",
       "0     0.107512  0.008089  \n",
       "1     0.107512  0.008089  \n",
       "2     0.107433  0.008048  \n",
       "3     0.107417  0.007960  \n",
       "4     0.107411  0.007911  \n",
       "...        ...       ...  \n",
       "5395  0.122200  0.065459  \n",
       "5396  0.121903  0.065412  \n",
       "5397  0.121905  0.065404  \n",
       "5398  0.121905  0.065396  \n",
       "5399  0.121905  0.065388  \n",
       "\n",
       "[5400 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicited Values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Waist_X</th>\n",
       "      <th>Waist_Y</th>\n",
       "      <th>Waist_Z</th>\n",
       "      <th>R_Foot_X</th>\n",
       "      <th>R_Foot_Y</th>\n",
       "      <th>R_Foot_Z</th>\n",
       "      <th>L_Foot_X</th>\n",
       "      <th>L_Foot_Y</th>\n",
       "      <th>L_Foot_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051660</td>\n",
       "      <td>0.993959</td>\n",
       "      <td>0.016173</td>\n",
       "      <td>0.222090</td>\n",
       "      <td>0.132332</td>\n",
       "      <td>0.083914</td>\n",
       "      <td>-0.122066</td>\n",
       "      <td>0.121406</td>\n",
       "      <td>0.076175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.051344</td>\n",
       "      <td>0.993858</td>\n",
       "      <td>0.016352</td>\n",
       "      <td>0.221845</td>\n",
       "      <td>0.132424</td>\n",
       "      <td>0.083953</td>\n",
       "      <td>-0.122258</td>\n",
       "      <td>0.121283</td>\n",
       "      <td>0.076357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.051032</td>\n",
       "      <td>0.993735</td>\n",
       "      <td>0.016537</td>\n",
       "      <td>0.221607</td>\n",
       "      <td>0.132492</td>\n",
       "      <td>0.084006</td>\n",
       "      <td>-0.122455</td>\n",
       "      <td>0.121172</td>\n",
       "      <td>0.076551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.050729</td>\n",
       "      <td>0.993622</td>\n",
       "      <td>0.016646</td>\n",
       "      <td>0.221353</td>\n",
       "      <td>0.132525</td>\n",
       "      <td>0.083994</td>\n",
       "      <td>-0.122683</td>\n",
       "      <td>0.121105</td>\n",
       "      <td>0.076637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.050317</td>\n",
       "      <td>0.993547</td>\n",
       "      <td>0.016730</td>\n",
       "      <td>0.220969</td>\n",
       "      <td>0.132555</td>\n",
       "      <td>0.083972</td>\n",
       "      <td>-0.123031</td>\n",
       "      <td>0.121052</td>\n",
       "      <td>0.076695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>-0.228640</td>\n",
       "      <td>1.004493</td>\n",
       "      <td>-0.026519</td>\n",
       "      <td>-0.041917</td>\n",
       "      <td>0.167162</td>\n",
       "      <td>0.009754</td>\n",
       "      <td>-0.370913</td>\n",
       "      <td>0.070193</td>\n",
       "      <td>0.054738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>-0.229919</td>\n",
       "      <td>1.005071</td>\n",
       "      <td>-0.027199</td>\n",
       "      <td>-0.043394</td>\n",
       "      <td>0.168772</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>-0.371351</td>\n",
       "      <td>0.068692</td>\n",
       "      <td>0.053163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>-0.231111</td>\n",
       "      <td>1.005592</td>\n",
       "      <td>-0.027668</td>\n",
       "      <td>-0.044772</td>\n",
       "      <td>0.170353</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>-0.371695</td>\n",
       "      <td>0.067181</td>\n",
       "      <td>0.051881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>-0.232154</td>\n",
       "      <td>1.006129</td>\n",
       "      <td>-0.027999</td>\n",
       "      <td>-0.045997</td>\n",
       "      <td>0.171867</td>\n",
       "      <td>0.005065</td>\n",
       "      <td>-0.371923</td>\n",
       "      <td>0.065749</td>\n",
       "      <td>0.050822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>-0.233086</td>\n",
       "      <td>1.006734</td>\n",
       "      <td>-0.028327</td>\n",
       "      <td>-0.047083</td>\n",
       "      <td>0.173345</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>-0.372079</td>\n",
       "      <td>0.064401</td>\n",
       "      <td>0.049878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5400 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Waist_X   Waist_Y   Waist_Z  R_Foot_X  R_Foot_Y  R_Foot_Z  L_Foot_X  \\\n",
       "0     0.051660  0.993959  0.016173  0.222090  0.132332  0.083914 -0.122066   \n",
       "1     0.051344  0.993858  0.016352  0.221845  0.132424  0.083953 -0.122258   \n",
       "2     0.051032  0.993735  0.016537  0.221607  0.132492  0.084006 -0.122455   \n",
       "3     0.050729  0.993622  0.016646  0.221353  0.132525  0.083994 -0.122683   \n",
       "4     0.050317  0.993547  0.016730  0.220969  0.132555  0.083972 -0.123031   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5395 -0.228640  1.004493 -0.026519 -0.041917  0.167162  0.009754 -0.370913   \n",
       "5396 -0.229919  1.005071 -0.027199 -0.043394  0.168772  0.007941 -0.371351   \n",
       "5397 -0.231111  1.005592 -0.027668 -0.044772  0.170353  0.006389 -0.371695   \n",
       "5398 -0.232154  1.006129 -0.027999 -0.045997  0.171867  0.005065 -0.371923   \n",
       "5399 -0.233086  1.006734 -0.028327 -0.047083  0.173345  0.003846 -0.372079   \n",
       "\n",
       "      L_Foot_Y  L_Foot_Z  \n",
       "0     0.121406  0.076175  \n",
       "1     0.121283  0.076357  \n",
       "2     0.121172  0.076551  \n",
       "3     0.121105  0.076637  \n",
       "4     0.121052  0.076695  \n",
       "...        ...       ...  \n",
       "5395  0.070193  0.054738  \n",
       "5396  0.068692  0.053163  \n",
       "5397  0.067181  0.051881  \n",
       "5398  0.065749  0.050822  \n",
       "5399  0.064401  0.049878  \n",
       "\n",
       "[5400 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Head_X</th>\n",
       "      <th>Head_Y</th>\n",
       "      <th>Head_Z</th>\n",
       "      <th>R_Controller_X</th>\n",
       "      <th>R_Controller_Y</th>\n",
       "      <th>R_Controller_Z</th>\n",
       "      <th>L_Controller_X</th>\n",
       "      <th>L_Controller_Y</th>\n",
       "      <th>L_Controller_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.074888</td>\n",
       "      <td>1.600794</td>\n",
       "      <td>-0.061166</td>\n",
       "      <td>0.298042</td>\n",
       "      <td>0.827012</td>\n",
       "      <td>-0.132336</td>\n",
       "      <td>-0.165098</td>\n",
       "      <td>0.809140</td>\n",
       "      <td>-0.101865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.074440</td>\n",
       "      <td>1.600455</td>\n",
       "      <td>-0.061601</td>\n",
       "      <td>0.298042</td>\n",
       "      <td>0.826655</td>\n",
       "      <td>-0.131672</td>\n",
       "      <td>-0.165177</td>\n",
       "      <td>0.809144</td>\n",
       "      <td>-0.101944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073985</td>\n",
       "      <td>1.600089</td>\n",
       "      <td>-0.062053</td>\n",
       "      <td>0.298042</td>\n",
       "      <td>0.826281</td>\n",
       "      <td>-0.131092</td>\n",
       "      <td>-0.165350</td>\n",
       "      <td>0.808988</td>\n",
       "      <td>-0.101994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.073546</td>\n",
       "      <td>1.599743</td>\n",
       "      <td>-0.062471</td>\n",
       "      <td>0.297867</td>\n",
       "      <td>0.826102</td>\n",
       "      <td>-0.130762</td>\n",
       "      <td>-0.165502</td>\n",
       "      <td>0.808815</td>\n",
       "      <td>-0.102003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.073038</td>\n",
       "      <td>1.599502</td>\n",
       "      <td>-0.062831</td>\n",
       "      <td>0.297403</td>\n",
       "      <td>0.825970</td>\n",
       "      <td>-0.130419</td>\n",
       "      <td>-0.165691</td>\n",
       "      <td>0.808677</td>\n",
       "      <td>-0.101968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>-0.201131</td>\n",
       "      <td>1.627999</td>\n",
       "      <td>-0.099943</td>\n",
       "      <td>0.021727</td>\n",
       "      <td>0.779983</td>\n",
       "      <td>-0.004333</td>\n",
       "      <td>-0.285726</td>\n",
       "      <td>0.921127</td>\n",
       "      <td>-0.282524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>-0.202731</td>\n",
       "      <td>1.627993</td>\n",
       "      <td>-0.099954</td>\n",
       "      <td>0.022384</td>\n",
       "      <td>0.780535</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>-0.278401</td>\n",
       "      <td>0.928770</td>\n",
       "      <td>-0.287716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>-0.204232</td>\n",
       "      <td>1.627990</td>\n",
       "      <td>-0.099949</td>\n",
       "      <td>0.023354</td>\n",
       "      <td>0.780641</td>\n",
       "      <td>0.006791</td>\n",
       "      <td>-0.271437</td>\n",
       "      <td>0.935878</td>\n",
       "      <td>-0.292777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>-0.205577</td>\n",
       "      <td>1.628091</td>\n",
       "      <td>-0.099872</td>\n",
       "      <td>0.024503</td>\n",
       "      <td>0.780717</td>\n",
       "      <td>0.012487</td>\n",
       "      <td>-0.264813</td>\n",
       "      <td>0.942567</td>\n",
       "      <td>-0.297453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>-0.206698</td>\n",
       "      <td>1.628358</td>\n",
       "      <td>-0.099758</td>\n",
       "      <td>0.025779</td>\n",
       "      <td>0.780819</td>\n",
       "      <td>0.018084</td>\n",
       "      <td>-0.258575</td>\n",
       "      <td>0.949295</td>\n",
       "      <td>-0.301889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5400 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Head_X    Head_Y    Head_Z  R_Controller_X  R_Controller_Y  \\\n",
       "0     0.074888  1.600794 -0.061166        0.298042        0.827012   \n",
       "1     0.074440  1.600455 -0.061601        0.298042        0.826655   \n",
       "2     0.073985  1.600089 -0.062053        0.298042        0.826281   \n",
       "3     0.073546  1.599743 -0.062471        0.297867        0.826102   \n",
       "4     0.073038  1.599502 -0.062831        0.297403        0.825970   \n",
       "...        ...       ...       ...             ...             ...   \n",
       "5395 -0.201131  1.627999 -0.099943        0.021727        0.779983   \n",
       "5396 -0.202731  1.627993 -0.099954        0.022384        0.780535   \n",
       "5397 -0.204232  1.627990 -0.099949        0.023354        0.780641   \n",
       "5398 -0.205577  1.628091 -0.099872        0.024503        0.780717   \n",
       "5399 -0.206698  1.628358 -0.099758        0.025779        0.780819   \n",
       "\n",
       "      R_Controller_Z  L_Controller_X  L_Controller_Y  L_Controller_Z  \n",
       "0          -0.132336       -0.165098        0.809140       -0.101865  \n",
       "1          -0.131672       -0.165177        0.809144       -0.101944  \n",
       "2          -0.131092       -0.165350        0.808988       -0.101994  \n",
       "3          -0.130762       -0.165502        0.808815       -0.102003  \n",
       "4          -0.130419       -0.165691        0.808677       -0.101968  \n",
       "...              ...             ...             ...             ...  \n",
       "5395       -0.004333       -0.285726        0.921127       -0.282524  \n",
       "5396        0.001099       -0.278401        0.928770       -0.287716  \n",
       "5397        0.006791       -0.271437        0.935878       -0.292777  \n",
       "5398        0.012487       -0.264813        0.942567       -0.297453  \n",
       "5399        0.018084       -0.258575        0.949295       -0.301889  \n",
       "\n",
       "[5400 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_values, actual_values, predicted_on_values = PredictModel(x_test, y_test, model_2)\n",
    "\n",
    "toWriteActual, toWritePred, toWritePredictedOn = DisplayPredictions(predicted_values, actual_values, predicted_on_values, 0, 0)\n",
    "\n",
    "display(toWritePredictedOn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Results to File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def WriteResultToFile(path, pred, actual, model, metrics, file_list, epochs, b_size, predicted_on):\n",
    "    try:\n",
    "        #get current date for folder naming\n",
    "        now = datetime.now()\n",
    "        dt_string = now.strftime(\"%d_%m_%Y_%H_%M\")\n",
    "    \n",
    "        #create new folder\n",
    "        new_folder = \"run_\" + dt_string\n",
    "        os.makedirs(path + new_folder)\n",
    "\n",
    "        #loop over columns to split between actual and predicted\n",
    "        for column in actual.columns:\n",
    "            new_column = \"A_\" + column\n",
    "            actual = actual.rename(columns={column : new_column})\n",
    "        for column in pred.columns:\n",
    "            new_column = \"P_\" + column\n",
    "            pred = pred.rename(columns={column : new_column})\n",
    "\n",
    "        #combine both actual and predicted dataframes\n",
    "        results = pd.concat([actual, pred], axis=1)\n",
    "    \n",
    "        #create output path for csv write\n",
    "        output_folder = results_path + new_folder\n",
    "    \n",
    "        predicted_on.to_csv(output_folder + \"/test_values.csv\", index = False, float_format = '%.6f')\n",
    "        results.to_csv(output_folder + \"/prediction.csv\", index = False, float_format='%.6f')\n",
    "        metric_labels = [\"Loss: \", \"Accuracy: \"]    \n",
    "        compile_params_list = [\"Loss Function: \", \"Optimizer: \", \"Metrics: \"]\n",
    "        #create new txt file to output model and training data summary\n",
    "        with open(output_folder + '/summary.txt','w') as fh:\n",
    "            model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "            fh.write(\"Epochs: \")\n",
    "            fh.write(str(epochs) + \"\\n\")\n",
    "            fh.write(\"Batch Size: \")\n",
    "            fh.write(str(b_size) + \"\\n\")\n",
    "            fh.write(\"Metrics:\\n\")\n",
    "            for i in range (len(metrics)):\n",
    "                fh.write(metric_labels[i])\n",
    "                fh.write(str(metrics[i]) + \"\\n\")\n",
    "            for i in range (len(compile_params)):\n",
    "                fh.write(compile_params_list[i])\n",
    "                fh.write(compile_params[i] + \"\\n\")\n",
    "            fh.write(\"Trained On:\\n\")\n",
    "            for file in file_list:\n",
    "                fh.write(file + \"\\n\")\n",
    "           \n",
    "        print(\"File Output to \" + new_folder)\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(e)\n",
    "        print(\"Error Writing Results To File!\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Output to run_07_08_2022_23_53\n"
     ]
    }
   ],
   "source": [
    "results_path = \"../results/\"\n",
    "\n",
    "WriteResultToFile(results_path, toWritePred, toWriteActual, model_2, results, files, epochs, batch_size, toWritePredictedOn) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "85273928d8596bf28b6a3fc4ded2b0665eee93193e52c7eff13f3a9a291ee5c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
